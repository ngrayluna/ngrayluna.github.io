<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Gray Luna</title>
    <link>https://ngrayluna.github.io/project/</link>
      <atom:link href="https://ngrayluna.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 07 Oct 2019 15:53:22 -0700</lastBuildDate>
    <image>
      <url>https://ngrayluna.github.io/img/icon-192.png</url>
      <title>Projects</title>
      <link>https://ngrayluna.github.io/project/</link>
    </image>
    
    <item>
      <title>Removing Noise from Seismic Data with Denoising Autoencoders</title>
      <link>https://ngrayluna.github.io/project/denoiser/</link>
      <pubDate>Mon, 07 Oct 2019 15:53:22 -0700</pubDate>
      <guid>https://ngrayluna.github.io/project/denoiser/</guid>
      <description>&lt;p&gt;&lt;a name =&#34;Intro&#34;&gt;From imaging the Earth&amp;rsquo;s interior like a giant CT scan, to locating new oil reserves, to detecting earthquakes, seismic waves provide us with a unique glimpse into our Earth’s interior.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To record these waves we use seismometers. Seismometers are highly sensitive instruments that typically measure translational ground motions. They are so sensitive that they are capable of measuring large, distant earthquakes from across the globe.&lt;/p&gt;

&lt;p&gt;Given their level of sensitivity, seismometers also pick up noise. This includes, but is not limited to: instrumental noise, changes in the Earth’s tides, pressure variations, and traffic. Seismologists therefore commonly apply filters to remove background noise, similar to what an audio-technician does when recording live music. However, knowing which filter to apply is not intuitive. Also, applying a filter might remove relevant information from the signal if the noise is in the same frequency band as the signal itself.&lt;/p&gt;

&lt;p&gt;Over the years there have been statistical efforts to remove noise without tampering the original signal. However, these methods usually require specifying some sort of variable threshold can lead to false signals if variables are selected incorrectly [5] [2].&lt;/p&gt;

&lt;p&gt;Because of this, we desire to find an alternative approach that can remove noise from seismic data, or denoise, with minimal to no human intervention. Additionally, we hope our method of denoising increases the signal-to-noise ratio of the signal. For the above mentioned reasons, we turned our sights toward deep neural networks.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#intro&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#understand&#34;&gt;Understanding the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model&#34;&gt;Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#processing&#34;&gt;Pre-Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#results&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#34;understand&#34;&gt;Understanding the Data&lt;/a&gt;&lt;/h2&gt; 

&lt;p&gt;How can we do this? Before we get into our model we need to first understand our data. Digital seismic data is a time series which can be described as a discrete sum of a number of sinusoids — each with a unique peak amplitude, frequency, and a phase-lag relative alignment [6]. As a result, we can take advantage of tools commonly used for signal processing.&lt;/p&gt;

&lt;p&gt;Typical processing of an audio file include: removing ambient noise, taking into account unequal distribution microphone recording, enhancing certain frequency bands and suppressing others, and so on. In recent years deep neural networks have been introduced to tackle some of this processing. Most famous are the applications of deep neural networks for automated speech recognition(ASR) such as Amazon&amp;rsquo;s Alexa and Apple&amp;rsquo;s Siri.&lt;/p&gt;

&lt;p&gt;&lt;img  src=&#34;./imgs/logos.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Logos of Apple’s Siri [left] and Amazon’s Alexa [right]. Both speech recognition systems use deep neural networks for automated speech recognition(ASR).&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Like seismic data, one of the challenges behind speech recognition is the presence of background noise, which convolutes the signal [3]. The challenge of removing noise (and thus improving the signal-to-noise ratio) in ASR parallels what the Seismological community faces when removing noise from seismic recordings. Instead of enhancing speech recordings, seismologists desire to enhance earthquake signals.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#34;model&#34;&gt;Model&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Before we decided which architecture to use, we did some research on current practices both within and outside the geophysical community. We did this because a) the deep learning field is constantly changing so an algorithm that is popular today may be shown to be inefficient tomorrow (I am looking at you RNN), b) we want to learn from other people’s mistakes and c) we wanted our approach to be unique.&lt;/p&gt;

&lt;p&gt;[5] approached the problem by first transforming their data into the frequency domain then using both the real and imaginary part as input to a convolutional neural network. [3] developed a denoising method based on a parametric dictionary learning scheme. Dictionary learning is a branch of signal processing and machine learning which exploits underlying sparse structures of the input training data. With these sparse representations, they were able to capture the characteristics of seismic data that could then be used for denoising. [1] used a combination of a U-net and incorporating a pre-trained neural network known as ResNet34. In doing so they took advantage of a feature extracting capabilities of CNN and the benefits of using pre-trained neural networks.&lt;/p&gt;

&lt;p&gt;Autoencoders are a type of Convolutional Neural Network that are used for unsupervised learning. If trained reliably, an autoencoder takes an input, converts it to a lower dimension, reconstruct the original dimension, then outputs something that looks similar to its original input. Assuming the model is trained to recreate the input, the hidden layer &amp;ldquo;bottleneck&amp;rdquo; in the neural network forces the autoencoder to contain information needed to represent the input but at a lower dimension. This makes autoencoders power feature extractors.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./imgs/denoiser_auto_model.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Denoising autoencoder model architecture used for training. The left portion (outlined in green on the top) depicts the encoder and the right portion (outlined in orange on top) is the decoder. If trained to reconstruct its input reliably, the coding (center dark blue block where the bottleneck occurs) is able to represent the input but at a lower dimension.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;To prevent the autoencoder from trivially learning its input, the input is corrupted; thereby forcing the autoencoder to learn useful features. In order to reduce the corruption process, the neural network learns/captures the probabilistic distribution of the input. We call this type of autoencoder, where the input has been corrupted with noise added to it, denoising autoencoders.&lt;/p&gt;

&lt;p&gt;We defined our denoising autoencoder with alternating convolutional and maxpooling layers for the encoder, and alternating upsampling and convolutional layers for the decoder portion of the DAE.&lt;/p&gt;

&lt;p&gt;There does not exist a predefined set of rules for knowing which hyperparameters to use for a given model. We got a ‘ballpark’ idea of what types of parameters to use by reading literature about similar machine learning projects and through trial-and-error.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#34;processing&#34;&gt;Pre-Processing&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Given the rich history of earthquake monitoring in California we were able to download seismic data from the Northern California Earthquake Data Center (NCEDC). We chose stations in Northern California that are known to have high signal-to-noise ratio. We queried events that were located within a 300km radius around each station. This was done to limit the length of our input training data to five-minute records. We also set a minimum earthquake magnitude threshold so that the starting SNR was large enough to preserve the earthquake signal. With this criterion we found approximately 10,000 unique station recordings within an 18-year time span.&lt;/p&gt;

&lt;p&gt;Each component of our records (Z, N, E) were treated as a &amp;ldquo;unique&amp;rdquo; instance. We thus expanded our training set by a factor of three, giving us approximately 30,000 training instances. Waveforms were detrended, high-passed filtered with a maximum frequency of 0.5Hz, and normalized. We then decimated our traces by a factor of two. This was done to reduce the number of parameters the machine learning algorithm would have to learn and work with during training.&lt;/p&gt;

&lt;p&gt;Our denoising autoencoder needs two inputs: an input x and a corrupted version $x$. To create a corrupted version $x_{i}$, we downloaded data between earthquake events from stations with poor SNR. We took this noise and added it to a copy of our pre-processed data. This left us with two versions: a clean version and a noisy/corrupted version. The noisy waveform and its associated original clean version are the input and label to our denoiser autoencoder, respectively.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#34;results&#34;&gt;Preliminary Results&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;To get a first taste of our model’s performance we turned to the learning (sometimes called the loss) curve. With increase epoch, the predictions made by the algorithm should improve, thus decreasing the cost. The plot below shows our model’s currently performance (as of 07.10.19).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./imgs/model_loss_epch1200.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Loss curve computed for the training (red curve) and validation (blue curve) set during training from our denoising autoencoder model. Note how the model was stuck at a saddle point between epoch 15 - 210. Training was stopped when the curves plateaued in order to prevent overfitting.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;The cost for both the training and validation set is decreasing with epoch. Our validation curve is nosier than our training curve which could suggest we need to modify our batch sizes or that the data within our validation set is semi-irregular and thus leads varying levels of loss per epoch. However, the fact the validation curve has a decreasing trend is promising. Note that the model was stuck at a saddle point about 15 – 210 epochs in and thus making our model take longer to improve.&lt;/p&gt;

&lt;p&gt;Learning curves give us insight to whether or not or model is learning, however, it doesn’t tell us much about the time-series output. The denoiser is spitting out waveforms that have (or should have) had noise removed.&lt;/p&gt;

&lt;p&gt;If noise has been removed, then we expect the signal-to-noise ratio to increase after the denoiser is applied. Let’s plots this. Below is the SNR before and after our denoiser is applied on the test set:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./imgs/snr_hist_TESTSET_1005.783.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Histogram of the signal-to-noise ratio of the the noisy/corrupted version (yellow) and the denoised version from our DAE (purple) using the pre-trained model on the test set.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Not bad! If we compare the SNR before and after running the model we can see that the mode goes from ~3dB to ~10dB.  Very promising.&lt;/p&gt;

&lt;p&gt;But, we need to talk about physics before we celebrate. Seismic data is a means by which we can learn about the interior of the Earth. Thus, we need to check what, if any, of the underlying physics that created the waveforms were preserved from using our DAE.  Two metrics we can look at are: changes in amplitude and changes in phase arrival times (i.e. the onset of the p-wave).&lt;/p&gt;

&lt;p&gt;Below we show the values of the peak (or max) amplitude of the waveforms as a function of their original amplitudes using a linear least sqaures polynomial fit. The black curve shows the original amplitude and is used as a reference for us to compare how the amplitudes changed when we both added noise (red line) and after it was denoised (purple). Looking at the plot we note that adding noisy increases the peak amplitude values for the data set. We would hope to see that using the denoising autoencoder will restore the original amplitude and thus give us a linear trend with a similar slope as the original. However, it would seem that overall the DAE is unable to return the peak amplitude values as can be seen with the purple linear fit curve which has a slope less than one.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./imgs/max_amp_demo.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Max amplitude of the waveforms as a function of their original amplitudes using a linear least sqaures polynomial fit. The original, non corrupted data (black curve), has a slope of 1 (since it is a function of itself). The red and purpled curves show the linear trend of the noisy input (red) and denoised (purple), respectively.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Le&amp;rsquo;t turn our attention arrival times of the p-wave. To find the p-wave arrival time we used and automated phase picker by &lt;a href=&#34;https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/77/4/1437/119016/An-automatic-phase-picker-for-local-and?redirectedFrom=PDF&#34; target=&#34;_blank&#34;&gt;Baer et. al&lt;/a&gt; on our three data sets: the original waveforms, the noisy (corrupted) waveforms, and the denoised waveforms. We then computed the difference in picked arrival times between the original and the denoised (purple) and the original and the corrupted/noisy waveforms (red line). The results are shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src = &#34;./imgs/time_diff_post.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Difference in picked arrival times between the original and the denoised (purple) and the original and the corrupted/noisy waveforms (red line). A linear least sqaures polynomial was used to fit the data.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Once againg we use linear least sqaures polynomial to fit our data and plot it as a function of the SNR before denoising. Though the automated phase picker is not picking the same p-wave arrival as the uncorrupted version (if this was the case the purple line would have a slope of 0), it does however pick p-arrivals closer to the true value (as we can see by the smaller differences in arrival time).&lt;/p&gt;

&lt;p&gt;This is where our model currently stands. We have a few items on our to do list which we think can help our model. We will go over some possible routes in the next section.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name=future&gt;Future Work&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;One of the first items on our to-do list is to check whether data augmentation (increases your data size via varying copies of your data set) will help our model reach lower cost values and/or converge more quickly. One option could be to modify the noise levels we are adding to our waveforms. While the information gain won&amp;rsquo;t be as significant as using more unique data, it should nonetheless improve our model.&lt;/p&gt;

&lt;p&gt;If we expand our training data set (either by data augmentation or downloading data from other stations) we will likely check if using a model with more hidden layers might be necessary. As a rule of thumb one should start with a shallow and then add more layers if necessary. If have practiced this and as of right now our model is fairly basic in comparison to other models. (Sorry, I can&amp;rsquo;t share more details because we are still working on this project).&lt;/p&gt;

&lt;p&gt;From a geophysicists point of view there is still a lot of questions that need to be answered. And, from the broader science point of view, there are questions about what place ML should have in advancing scientific exploration. What we do know is that DNN are showing promising results. How we evaluate them, how we ensure reproducibility, etc. are topics which remain to be seen.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#34;references&#34;&gt;References&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;[1] Alan Richardson and Caelen Feller. &amp;ldquo;Seismic data denoising and deblending using deep learning&amp;rdquo;. (2019).&lt;/p&gt;

&lt;p&gt;[2] Li-ping Zhang et al. &amp;ldquo;Seismic Signal Denoising and Decomposition Using Deep Neural Networks&amp;rdquo;. In: International Journal of Petrochemical Science &amp;amp; En- gineering (2017).&lt;/p&gt;

&lt;p&gt;[3] Lingchen Zhu, Entao Liu, and James H. McClellan. &amp;ldquo;Seismic data denoising through multiscale and sparsity-promoting dictionary learning&amp;rdquo;. In: Geo-
physics 80 (2015).&lt;/p&gt;

&lt;p&gt;[4] Mike Kayser and Victor Zhong. &amp;ldquo;Denoising Convolutional Autoencoders for Noisy Speech Recognition&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;[5] Weiqiang Zhu and Gregory C. Beroza. &amp;ldquo;PhaseNet: A Deep-Neural-Network-Based Seismic Arrival Time Picking Method&amp;rdquo;. In: Geophysics Journal Inter-
national 216 (2018), pp. 261-273.&lt;/p&gt;

&lt;p&gt;[6] Öz Yilmaz. &amp;ldquo;Introduction to fundamentals of signal processing&amp;rdquo;. (2001) &lt;a href=&#34;https://wiki.seg.org/wiki/Introduction_to_fundamentals_of_signal_processing&#34; target=&#34;_blank&#34;&gt;https://wiki.seg.org/wiki/Introduction_to_fundamentals_of_signal_processing&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;
</description>
    </item>
    
  </channel>
</rss>
