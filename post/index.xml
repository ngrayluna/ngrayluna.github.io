<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Gray Luna</title>
    <link>https://ngrayluna.github.io/post/</link>
      <atom:link href="https://ngrayluna.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 30 Sep 2019 22:14:26 -0700</lastBuildDate>
    <image>
      <url>https://ngrayluna.github.io/img/icon-192.png</url>
      <title>Posts</title>
      <link>https://ngrayluna.github.io/post/</link>
    </image>
    
    <item>
      <title>Identifying Seismic Waves with Convolutional Neural Networks [Part I]</title>
      <link>https://ngrayluna.github.io/post/p-phase-picker-tutorial_pi/</link>
      <pubDate>Mon, 30 Sep 2019 22:14:26 -0700</pubDate>
      <guid>https://ngrayluna.github.io/post/p-phase-picker-tutorial_pi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./img/Neurons-Network_T.jpg&#34;&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a name=&#34;intro&#34;&gt;Introduction&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Earthquakes are unpredictable. And if you are a Californian Native like me (or happen to live near an active earthquake fault), chances are you have felt ground shaking caused by an earthquake. There is no algorithm to predict earthquakes. However, the physics governing seismic wave propagation allow us to prepare ourselves from  shaking once an earthquake has occured.&lt;/p&gt;

&lt;p&gt;Seismic waves travel slower than light (i.e. the speed at which emails, txts, travel). It is therefore possible to send a warning about incoming ground motion shaking after an earthquake has occured. This is the main idea behind &lt;a href=&#34;https://seismo.berkeley.edu/research/eew_basics.html#targetText=What%20is%20Earthquake%20Early%20Warning,how%20big%20the%20earthquake%20is&#34; target=&#34;_blank&#34;&gt;Earthquake Early Warning&lt;/a&gt;. The idea being that, if we are a certain distance away from the earthquake hypocenter, we could send a warning (somewhere between seconds to a minute or two) via a txt, email, app. etc to someone else who is in the direction of the incoming seismic waves.&lt;/p&gt;

&lt;p&gt;In order to send an earthquake early warning, however, seismologists need to have a high level of certainty that: 1) the ground motion recorded by a seismometer is in fact an earthquake and not background noise (e.g. someone walking near a sensor) and 2) the location of the earquake.&lt;/p&gt;

&lt;p&gt;Luckily we have computers to accomplish this. Unfortunately, typical detection systems take about a minute to send an earthquake alert. This is partly due to the fact that it takes time to both: get enough information from several seismometers and process the data.&lt;/p&gt;

&lt;p&gt;Can Machine Learning, specifically Deep Learning, give us an alternative approach? An approach which is more accurate and/or faster? More specifically, can we train a deep neural network to help us identify features in seismic records which will allow us determine if an earthquake has occured and if yes, where is it?&lt;/p&gt;

&lt;p&gt;To make OUR grandiose problem more manageable, we will boil this problem down to a much simpler one:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;b&gt;&lt;span style=&#34;font-family:Helvetica Neue; font-size:1.4em;&#34;&gt;&amp;ldquo;Can we train a deep neural network to identify the first seismic wave recorded on a seismometer?&amp;rdquo;&lt;/span&gt;&lt;/b&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;In other words, let&amp;rsquo;s assume we have already identified the seismic record is in fact an earthquake. Our task is to now identify the location of the earthquake. To do this we need to know when the incoming wave was first spotted. In other words, we need to know when the first seismic phase has arrived. This phase is known as the Primary Phase (or P-wave) and is marked with a red vertical line in the image below.&lt;/p&gt;

&lt;p&gt;&lt;img src = &#34;./img/2838868.GR.WET_mod.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Earthquake recorded by a seismometer in Wettzell, Germany. The red vertical line notes the Primary Phase, the first seismic phase recorded by the seismometer. The blue vertical line depicts another type of surface phase known as the Secondary Phase. To identify the phases a human (or computer) is looking for a change in both amplitude and frequency.  The x axis is in units of number of samples (npts).&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
The p-wave travels the faster than other phases (e.g. the S-phase shown above), however the frequency and the polarization (direction) of these waves tends to not cause structural damage (depending on how large the earthquake is, of course). The more destructive seismic phases, known as surface waves, take longer to arrive than the p-wave. The further you are from the earthquake, the larger the time lag between the p-wave and these  destructive surface waves. Thus, if we can detect the p-wave (and accurately) we can then compute how much time a person has before they should expect ground motion shaking.&lt;/p&gt;

&lt;p&gt;In this two-part tutorial we will establish the following machine learning workflow:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Download seismic data&lt;/b&gt; → &lt;b&gt;Pre-process data &amp;amp; format it for training&lt;/b&gt; → &lt;b&gt;Decide which DNN to use and create it&lt;/b&gt; → &lt;b&gt;Train model&lt;/b&gt; → &lt;b&gt;Analyze Results&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;For the sake of making the tutorial a little more digestable, we will split the tutorial into two parts. Part I (this post) will focus on: framing the problem, how to download data, and pre-processing the data we have downloaded.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#intro&#34;&gt;Introduction&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#frame&#34;&gt;Framing the Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#download&#34;&gt;Downloading Seismic Data&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pre_process&#34;&gt;Pre-Process&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#download&#34;&gt;Saving the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#34;frame&#34;&gt;Framing the Problem&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s begin! Before we download data let&amp;rsquo;s go over the details of how we will accomplish our objective.  Remember our goal is to identify where the first seismic phase, i.e. the p-wave, is in our records. Our plan of attack will be to use a Convolutional Neural Network (CNN). Convolutional neural networks are a type of deep neural network that handle data that is either time or spatially dependent, such as seismograms (time-dependency) or images (spatial dependency) just to name a couple of examples.&lt;/p&gt;

&lt;p&gt;Our data will consist of seismograms of earthquake events recorded by seismometers in California. The seismic records we collect and process are the input to our CNN. Our labels will consist of scalar-valued, p-wave picks made by seismologists (e.g. the point the vertical line crosses on the x-axis in the image above).  Thus, for each training instance, we will give our CNN a seismic record (time-series array) as input, x, and its associated p-wave location as its label, y.&lt;/p&gt;

&lt;p&gt;During training our neural network will try to identify which features are relevant in the waveforms that allow it to accurately determine where the p-wave. Visually, we as humans can tell where this is by looking in a sudden chance in both frequency and amplitude.&lt;/p&gt;

&lt;p&gt;In our case we have two different options of how we can feed our CNN our data. We can either feed it images or we can keep the data in arrays. If we choose the former, we will need to define a 2D convolutional neural network. Alternatively, we can use a 1D CNN and keep our data in arrays. Since I want to have as output arrays for further processing, I’ll keep my data in its original 1D format, as it will make future analysis easier.&lt;/p&gt;

&lt;p&gt;Groovy. We now have a more solid outline of what we need to do. Let’s now download some data!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#34;download&#34;&gt;Downloading Seismic Data&lt;/a&gt;&lt;/h2&gt;  

&lt;p&gt;Now that we have a gameplan, let’s get our hands dirty and download some seismic data. Luckily for us, the vast majority of earthquake data centers are open and free for public use. In California there are two well-known data centers, the Northern California Earthquake Data Center and the Southern California Data Center.&lt;/p&gt;

&lt;p&gt;We’ll use data recorded from stations in Northern California. You can find a list of stations, their state of health, and history from the
&lt;a href=&#34;http://ncedc.org/&#34; target=&#34;_blank&#34;&gt;NCEDC&lt;/a&gt; website.&lt;/p&gt;

&lt;p&gt;&lt;img src =&#39;./img/ca_seismic_stations.png&#39;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Subset of seismic stations in Northern California. Yellow circles depict broadband stations and blue depict borehole stations. Courtesy of the NCEDC.&lt;/p&gt;

&lt;p&gt;I will pick some of my personal favorite stations for this tutorial, but feel free to check out others and see what their data looks like in comparison. There is a nifty Python library known as &lt;a href=&#34;https://github.com/obspy/obspy/wiki&#34; target=&#34;_blank&#34;&gt;ObsPy&lt;/a&gt; which makes accessing seismic data quick and easy. Let&amp;rsquo;s import ObsPy along with some other Python libraries and check out how our data looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import numpy as np
import pandas as pd
from obspy.clients.fdsn import Client
from obspy import Stream, UTCDateTime
from obspy.core.event import read_events


import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s look at how one of these events look like as recorded by a broadband seismometer. You&amp;rsquo;ll notice that in this example I have picked a specific network, station, and channels. Feel free to use * to specify all in ObsPy. This will return a list of several networks, stations, locations, and channels to use for the time duration specified for start time and end time parameters.&lt;/p&gt;

&lt;p&gt;For the sake of having a &amp;lsquo;nice&amp;rsquo; waveform to look at, I&amp;rsquo;ll manually specify the time of a known earthquake event. (There are more clever ways of querying for earthquakes, but let’s keep it simple and look at just one example). Specifically, I&amp;rsquo;ll download a &lt;a href=&#34;https://earthquake.usgs.gov/earthquakes/eventpage/nc73286930/executive&#34; target=&#34;_blank&#34;&gt;recent (as of writting this post) earthquake&lt;/a&gt; off the cost of San Francisco.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;network = &amp;quot;BK&amp;quot;
station = &amp;quot;CMB&amp;quot;
location = &amp;quot;*&amp;quot;
channel = &amp;quot;BH*&amp;quot;
starttime = UTCDateTime(&amp;quot;2019-10-05T15:40:00&amp;quot;)
endtime = starttime + 300

client  = Client(&amp;quot;NCEDC&amp;quot;)
stream = client.get_waveforms(network = network, station = station, location = location,\
                              channel = &amp;quot;BH*&amp;quot;, starttime=starttime, endtime=endtime)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Quick Note About ObsPy&#39;s Stream Object&lt;/h3&gt;

&lt;p&gt;The following is directly from [ObsPy&amp;rsquo;s Documentation] page (&lt;a href=&#34;https://docs.obspy.org/packages/obspy.core.html):&#34; target=&#34;_blank&#34;&gt;https://docs.obspy.org/packages/obspy.core.html):&lt;/a&gt;
Seismograms of various formats (e.g. SAC, MiniSEED, GSE2, SEISAN, Q, etc.) can be imported into a Stream object using the &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;read()&lt;/span&gt; function.&lt;/p&gt;

&lt;p&gt;Streams are list-like objects which contain multiple Trace objects, i.e. gap-less continuous time series and related header/meta information.&lt;/p&gt;

&lt;p&gt;Each Trace object has the attribute data pointing to a NumPy ndarray of the actual time series and the attribute stats which contains all meta information in a dict-like Stats object. Both attributes starttime and endtime of the Stats object are UTCDateTime objects. A multitude of helper methods are attached to Stream and Trace objects for handling and modifying the waveform data.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;For example, for each recording our station records motion in three different directions: a vertical motion (up-down) and two horizontal motions (N-S and E-W).  Thus, our &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Stream&lt;/span&gt; object has three &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Traces&lt;/span&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;stream
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3 Trace(s) in Stream:
BK.CMB.00.BHE | 2019-10-05T15:40:00.019538Z - 2019-10-05T15:44:59.994538Z | 40.0 Hz, 12000 samples
BK.CMB.00.BHN | 2019-10-05T15:40:00.019538Z - 2019-10-05T15:44:59.994538Z | 40.0 Hz, 12000 samples
BK.CMB.00.BHZ | 2019-10-05T15:40:00.019538Z - 2019-10-05T15:44:59.994538Z | 40.0 Hz, 12000 samples
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each Trace object has head information which we can access by printing the attributes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace0 = stream[0]
print(trace0.stats)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;               network: BK
               station: CMB
              location: 00
               channel: BHE
             starttime: 2019-10-05T15:40:00.019538Z
               endtime: 2019-10-05T15:44:59.994538Z
         sampling_rate: 40.0
                 delta: 0.025
                  npts: 12000
                 calib: 1.0
_fdsnws_dataselect_url: http://service.ncedc.org/fdsnws/dataselect/1/query
               _format: MSEED
                 mseed: AttribDict({&#39;dataquality&#39;: &#39;D&#39;, &#39;number_of_records&#39;: 7, &#39;encoding&#39;: &#39;STEIM2&#39;, &#39;byteorder&#39;: &#39;&amp;gt;&#39;, &#39;record_length&#39;: 4096, &#39;filesize&#39;: 81920})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll use this information to make some useful unit conversions in our plots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sampling_rate = trace0.stats.sampling_rate
npts  = trace0.stats.npts
delta = trace0.stats.delta

time = np.arange(0, npts / sampling_rate, delta)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Plotting this with Python&amp;rsquo;s &lt;a href=&#34;https://matplotlib.org/&#34; target=&#34;_blank&#34;&gt;Matplotlib&lt;/a&gt; we have:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rows = 3
fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize = (16,10))
axes[0].plot(time, stream[0], color = &#39;black&#39;)
axes[1].plot(time, stream[1], color = &#39;black&#39;)
axes[2].plot(time, stream[2], color = &#39;black&#39;)
axes[rows - 1].set_xlabel(&#39;Time [s]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Text(0.5,0,&#39;Time [s]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src =&#34;./img/output_12_1.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;In addition to the training data we will need to also provide labels to our CNN. We are interested in training a CNN to identify the first arriving seismic phase, the p-wave. We can manually identify this by looking at the waveform and searching for a time where both the frequency and amplitude of the waveform changes drastically. In our example we can see this occurring at around 30 seconds.  This is the label we will provide to our neural network.&lt;/p&gt;

&lt;p&gt;Manually picking our entire data set is something we would have to do IF it were not for the fact that the NCEDC has had individuals manually pick earthquakes for decades and provided it for all to use. We’ll take advantage of their hardwork and simply make a query to download waveforms and their associated p-phase arrival time and store it into a Pandas DataFrame.&lt;/p&gt;

&lt;p&gt;To find the manually picked phase arrival we&amp;rsquo;ll search through the archived catalogue of events using ObsPy&amp;rsquo;s &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;get_events()&lt;/span&gt; method.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Minimum magnitude earthquake to search for
minmag = 3.0

# Maximum search radius around station to look for events
maxrad = 2.697

stla = 38.03
stlo = -120.39

cat = client.get_events(starttime=starttime, endtime=endtime, latitude=stla, longitude=stlo,\
                        maxradius=maxrad, minmagnitude=minmag,\
                        includearrivals = True)
print(cat)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1 Event(s) in Catalog:
2019-10-05T15:41:06.570000Z | +37.660, -122.521 | 3.54 Mw | manual
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;station_picks = []
for n, event in enumerate(cat):
    origin_info = event.origins[0].arrivals
    
    for i, pick in enumerate(event.picks):
        onset = pick.onset
        polarity = pick.polarity
        evaluation_mode = pick.evaluation_mode
        evaluation_status = pick.evaluation_status
        phase_time = pick.time

        arrival = origin_info[i]
        pick_id = pick.resource_id
        pid = arrival[&#39;pick_id&#39;]
        
        if pid != pick_id:

            new_arrival = \
                [arrival for arrival in origin_info if arrival[&#39;pick_id&#39;] == pick_id]
            if len(new_arrival) &amp;lt; 1:
                continue
            phase = new_arrival[0][&#39;phase&#39;]
        else:
            phase = arrival[&#39;phase&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# EventID
eventID = event.resource_id.id.split(&#39;/&#39;)[-1]

# Let&#39;s convert from UTC to something we can work with
p_arrival = abs(stream[0].stats.starttime.timestamp - phase_time.timestamp)

print(&amp;quot;EventID {}&amp;quot;.format(eventID))
print(&amp;quot;First seismic wave arrives {} seconds from the start of our record.&amp;quot;.format(round(p_arrival, 3)))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;EventID 73286930
First seismic wave arrives 91.86 seconds from the start of our record.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s plot this to see how this looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;time = np.arange(0, stream[0].stats.npts / stream[0].stats.sampling_rate, stream[0].stats.delta )

fig, axes = plt.subplots(nrows = 1, ncols = 1 , figsize = (16,6))
axes.plot(time, stream[0].data, color = &#39;black&#39;)
axes.axvline(p_arrival, color = &#39;red&#39;)
axes.set_xlabel(&amp;quot;Time [s]&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Text(0.5,0,&#39;Time [s]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img srce =&#34;./img/output_18_1.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;As expected the p-arrival is pick made by the human analyst was made when there was a change in amplitude and frequency. In this case this happens at around 350 seconds.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#34;pre_process&#34;&gt;Pre-Processing&lt;/a&gt;&lt;/h2&gt;  

&lt;p&gt;If you have experience with signal processing, you already know there are a slew of tools to process audio recordings. We can use similar processing tools for seismic data. In particular, we’ll want to remove trends and filter out unwanted noise. Let’s do that with some of Stream&amp;rsquo;s useful methods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Both the detrend() and filter() operation is performed in place of the actual arrays.
# Let&#39;s make a copy of this Stream in order to have access to the original. 
st = stream.copy()

# Detrend
st.detrend()

# Apply high pass filter
max_freq = (1/2)
st.filter(type=&amp;quot;highpass&amp;quot;, freq = max_freq)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3 Trace(s) in Stream:
BK.CMB.00.BHE | 2019-10-05T15:40:00.019538Z - 2019-10-05T15:44:59.994538Z | 40.0 Hz, 12000 samples
BK.CMB.00.BHN | 2019-10-05T15:40:00.019538Z - 2019-10-05T15:44:59.994538Z | 40.0 Hz, 12000 samples
BK.CMB.00.BHZ | 2019-10-05T15:40:00.019538Z - 2019-10-05T15:44:59.994538Z | 40.0 Hz, 12000 samples
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Plotting the waveforms after applying our filters you&amp;rsquo;ll notice that the traces have less noise before the p-wave and after the signal trails off.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rows = 3
fig, axes = plt.subplots(nrows = rows, ncols = 1, figsize = (16,10))
axes[0].set_title(&amp;quot;Event ID {}&amp;quot;.format(eventID))
axes[0].plot(time, st[0], color = &#39;black&#39;)
axes[1].plot(time, st[1], color = &#39;black&#39;)
axes[2].plot(time, st[2], color = &#39;black&#39;)
axes[rows - 1].set_xlabel(&amp;quot;Time [s]&amp;quot;)

for i in range(rows):
    axes[i].axvline(p_arrival, color = &#39;red&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src = &#34;./img/output_23_0.png&#34;&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a name = &#34;download&#34;&gt;Saving the Data&lt;/a&gt;&lt;/h2&gt;  

&lt;p&gt;There are several file format options we have at our disposal. To keep things simple, we&amp;rsquo;ll use NumPy&amp;rsquo;s array method &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;np.savez_compressed()&lt;/span&gt;, which is NumPy&amp;rsquo;s way of saving arrays into a compressed file format with file extension &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;.npz&lt;/span&gt;. Once we have done a mass download of our waveforms, we&amp;rsquo;ll save our NumPy arrays using somthing like:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;np.savez_compressed(array, file_name)&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;where &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;array&lt;/span&gt; is a NumPy array with all of our seismograms and &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;file_name&lt;/span&gt; is the name of the output file our NumPy arrays are saved in. For example, in this tutorial I used:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;np.savez_compressed(&amp;lsquo;./dataset_3comp.npz&amp;rsquo;, clean_data_set)&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll also need to make sure we save a separate NumPy array which will contains our labels, the p-wave picks. For example:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;np.savez_compressed(&amp;lsquo;./dataset_3comp_cleanlabels.npz&amp;rsquo;, clean_labels)&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;See the associated &lt;a href =&#34;https://github.com/ngrayluna/P_Phase_Picker&#34;&gt;GitHub repository&lt;/a&gt; for the more technical details on how I did this.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#34;summary&#34;&gt;Summary&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;In this tutorial we formally stated the problem, broke down a complicated problem into a more manageable one, downloaded time-series data and manually picked phase information, processed the data by applying filters and demeaning it, and we ended by saving it into a compressed file format (.npz). In the next blog we will go over how to: read in saved training data labels, format the data for training, build a baseline CNN model, train said model, make first-and make first-order interpretations.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h3&gt;Suggest Reading Material&lt;/h3&gt;  

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Ackermann, Nils. &amp;ldquo;Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences&amp;rdquo; &lt;i&gt;Medium&lt;/i&gt;, 04 September 2018, &lt;a href=&#34;https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf&#34; target=&#34;_blank&#34;&gt;https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Géron, A. (2017). Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems. O&amp;rsquo;Reilly UK Ltd.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://seismo.berkeley.edu/research/eew_basics.html#targetText=What%20is%20Earthquake%20Early%20Warning,how%20big%20the%20earthquake%20is&#34; target=&#34;_blank&#34;&gt;Information on Earthquake Early Warning&lt;/a&gt; provided by the U.C. Berkeley Seismological Laboratory&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stanford CS class CS231n: &lt;a href=&#34;http://cs231n.github.io/&#34; target=&#34;_blank&#34;&gt;Convolutional Neural Networks for Visual Recognition&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Identifying Seismic Waves with Convolutional Neural Networks [Part II]</title>
      <link>https://ngrayluna.github.io/post/p-phase-picker-tutorial/</link>
      <pubDate>Tue, 01 Oct 2019 01:00:00 +0000</pubDate>
      <guid>https://ngrayluna.github.io/post/p-phase-picker-tutorial/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;./img/Neurons-Network_T.jpg&#34;&gt;&lt;/p&gt;

&lt;p&gt;In &lt;a href =&#34;https://ngrayluna.github.io/post/p-phase-picker-tutorial_pi/&#34;&gt;Part I&lt;/a&gt; we covered the first steps of our machine learning pipeline: &lt;b&gt;Framing the Problem&lt;/b&gt;, &lt;b&gt;Retrieving the Data &lt;/b&gt;, &lt;b&gt;Exploring and Understanding your Data&lt;/b&gt;, and &lt;b&gt;Processing the Data for training &lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;In this tutorial we will go sraight into &lt;b&gt;compiling&lt;/b&gt;, &lt;b&gt;training&lt;/b&gt;, and &lt;b&gt;evaluating&lt;/b&gt; a baseline convolutional neural network.  We&amp;rsquo;ll end by going over what still needs to be done before we can consider this model ready for deployment.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#read_data&#34;&gt;Read Data In&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cnn_baseline&#34;&gt;A Convolutional Neural Network Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#train_model&#34;&gt;Training Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interpreting_results&#34;&gt;Interpreting the Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualize_results&#34;&gt;Visualizing the Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#whats_next&#34;&gt;What&amp;rsquo;s Next&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br&gt;
To begin, let&amp;rsquo;s import some modules and functions that will be useful later:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import numpy as np
import pandas as pd
from random import randint
from keras.layers import Input, Dense
from keras.layers import Conv1D, MaxPooling1D, UpSampling1D
from keras.layers.normalization import BatchNormalization
from keras.layers import Dropout, Activation, Flatten
from keras.models import Model
from keras.models import model_from_json

import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def form_WAVsaved_npz(data_array):
    tmp_list = []
    for array in data_array:
        tmp_list.append(data_array[array])

    # Convert to Numpy array
    # (# of instances, # of features)
    data_array = np.array(tmp_list)  

    # From (1, 7156, 3, 1800) to (7156, 3, 1800)
    data_array = data_array.reshape(data_array.shape[1], data_array.shape[2], data_array.shape[3])

    return data_array

def format_Psaved_npz(label_array):
    tmp_list = []
    for array in label_array:
        tmp_list.append(label_array[array])

    # Convert to Numpy array
    # (# of instances, # of features)
    data_array = np.array(tmp_list)  

    # (1, #samples, labels)
    labels = data_array.reshape(data_array.shape[1])
    
    return labels
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;h2&gt;&lt;a name=&#39;read_data&#39;&gt;Read Data In&lt;/a&gt;&lt;/h2&gt;&lt;/p&gt;

&lt;p&gt;For this model we are using the data saved from our pre-processing efforts. There are a few different file formats for storing time-series data. Probably the most common file format you&amp;rsquo;ll come across are &lt;a href=&#34;https://www.hdfgroup.org/solutions/hdf5/&#34; target=&#34;_blank&#34;&gt;HDF5&lt;/a&gt; (Hierarchical Data Format) and NumPy&amp;rsquo;s .npz, which is NumPy&amp;rsquo;s way of saving arrays into a compressed file format. For this tutorial we will use .npz files.&lt;/p&gt;

&lt;p&gt;There are two files to read in: time-series waveforms and the arrival times of the first arriving (P-Phase) seismic wave. The latter of which are the labels we are using for our training model. Simply use &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;np.load()&lt;/span&gt; to read both .npz files in.  Once the files are read we&amp;rsquo;ll store them into NumPy arrays. I&amp;rsquo;ve written a function to then take this  &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;numpy.lib.npyio.NpzFile&lt;/span&gt; and store it into a NumPy array.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Let&#39;s read this in and check it is right.
data_waves = np.load(&amp;quot;./pre_process/waveforms.npz&amp;quot;)
data_labels = np.load(&amp;quot;./pre_process/labels.npz&amp;quot;)   # labels

data_array = form_WAVsaved_npz(data_waves)

p_arrivals = format_Psaved_npz(data_labels)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make our lives easier, we&amp;rsquo;ll also assign the number of traces, the number of features, and the number of sample points to variables
&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;num_traces&lt;/span&gt;, &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;num_feat&lt;/span&gt;, and &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;npts&lt;/span&gt;, respectively.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Number of traces
num_traces = data_array.shape[0]   # e.g. (1, 5, 3)

# Index of feature we want.
num_feat   = data_array.shape[2]

# npts
npts = data_array.shape[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We need to set aside some of our data set for training and set the remaining bit as our validation set.  The size of your data set determines what ratio of training to validation you&amp;rsquo;ll want to use. For &amp;ldquo;smaller&amp;rdquo; data sets it is common to use 80% of your data set for training and set aside the other 20% for validation. If you have a data set in the millions, then you&amp;rsquo;ll probably end up using 10% of your data for validation and the rest for training.&lt;/p&gt;

&lt;p&gt;To split our data set I am simply setting&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;TRAIN_TEST_SPLIT = 0.2&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;In other words, keep 80% for training.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Split data into training and validation 
# The percent of data that will be included in the test set (here 20%)
TRAIN_TEST_SPLIT = 0.2

# TRAIN/VAL split 
nr_val_data = int(num_traces * TRAIN_TEST_SPLIT)

x_train = data_array[nr_val_data:, :] # x composed of two traces
y_train = p_arrivals[nr_val_data :] # y values has the s-arrival time

x_val  = data_array[:nr_val_data, :]
y_val  = p_arrivals[: nr_val_data]
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#39;cnn_baseline&#39;&gt;A Convolutional Neural Network Baseline&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;We have read our data in, formatted into NumPy arrays, and we just split the data into a training and validation training set. Let&amp;rsquo;s define our deep neural network!  As stated in the title of this blog, we will be using convolutional neural networks (CNN). Among other things, CNN are designed to handle grid-like data such as time-series data and images. Alternatively, we could use a type of Recurrent Neural Network (RNN), which can also handle data with spatial-temporal dependencies, however let&amp;rsquo;s stick to CNNs as they are currently one of the most popular models in the field of Computer Vision.&lt;/p&gt;

&lt;p&gt;To create our convolutional neural network model we will use &lt;a href=&#34;https://keras.io/&#34; target=&#34;_blank&#34;&gt;Keras&lt;/a&gt; which is a high-level neural network API. It is fairly straight forward to use and the community supporting Keras is robust.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;h3&gt;Hyperparameter Choice&lt;/h3&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, there does not exist a set of rules which will tell you what hyperparameters you should use. The process of fine-tuning your model is empirical and requires a lot of trial and error.  However, that doesn&amp;rsquo;t mean you should start choosing randomly; read what model configurations is working for other groups and do a little homework on which parameters are appropriate.&lt;/p&gt;

&lt;p&gt;In our case we will use the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mini batches of 256 [memory on computers is stored in 2&amp;rsquo;s, so batches of a power of 2 helps train a little faster]&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;400 epochs [let&amp;rsquo;s just start with this]&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Filters size of 32 and 64&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Kernel size of size 6&lt;/li&gt;
&lt;li&gt;Pool size of 2&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Rectified linear unit (ReLU) activation function for the hidden layers&lt;/li&gt;
&lt;li&gt;Linear activation function for the output layer [we want an activation function which can give us values between -1 to 1]&lt;/li&gt;
&lt;li&gt;Mean squared error loss function&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Adam optimizer [best of RMSprop and gradient decent with momentum]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you have experience using convolutional neural networks, you&amp;rsquo;ll note that as input we can specify more than one channel. In the case of color images we define, and give as input, three channels as input: red, green, and blue. Hence, our input will have dimension:&lt;/p&gt;

&lt;p&gt;&lt;centre&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;(# training examples, number of samples, # of channels)&lt;/span&gt;&lt;/centre&gt;.&lt;/p&gt;

&lt;p&gt;The data recorded by the seismometers record motion in three directions: a vertical(up-down) and two horizontal motions (N-S and E-W). Thus, for each training example we will give our neural network not just one, but three waveforms. Thus, our input array will have three channels. Below is an illustration of what our CNN looks like:&lt;/p&gt;

&lt;p&gt;&lt;img src = &#39;./img/three_comp_cnn.png&#39;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Schematic of 1D convolutional neural network used to identify the first-arriving phase arrival of an earthquake. Note that each instance is composed of three channels, one for each component measuered by the seismometer (Vertical, North-South, East-West).&lt;/p&gt;

&lt;p&gt;For the sake of brevity, I&amp;rsquo;ll omit commentary on how we chose the number of hidden layers and the filter size (or sometimes referred to as &amp;lsquo;kernels&amp;rsquo;) in this blog. I&amp;rsquo;ll make a separate blog detailing the knitty-gritty details of how convolutional neural networks work.&lt;/p&gt;

&lt;p&gt;With this in mind let&amp;rsquo;s go ahead and make our convolutional neural network. Our input array, &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt; x_train&lt;/span&gt;, has input dimension of:&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll need to specify this for our model (see variable &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;input_trace&lt;/span&gt;). Below is a summary of our model. Each line describes a hidden layer and it&amp;rsquo;s associated number of weights and parameters.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Hyperparameters 
batch_size = 256
epochs     = 400
filters    = [32, 64]
kernel_size = 6
pool_size = 2
padding = &#39;same&#39;
hidden_act_fun = &#39;relu&#39;
final_act_fun  = &#39;linear&#39;
optimizer = &#39;adam&#39;
loss_type = &#39;mean_squared_error&#39; 
name = &#39;s_phase_picker&#39;

## MODEL ##
# Input placeholder
input_trace = Input(shape=(x_train.shape[1], x_train.shape[2]))  
x = Conv1D(filters = filters[0], kernel_size = kernel_size, activation=hidden_act_fun, padding = padding)(input_trace)
x = MaxPooling1D(pool_size = pool_size, padding = padding)(x)
x = Conv1D(filters = filters[1], kernel_size = kernel_size, activation=hidden_act_fun, padding = padding)(x)
x = MaxPooling1D(pool_size = pool_size, padding = padding)(x)
cnn_feat = Flatten()(x)

x = Dense(units= 32, activation=hidden_act_fun)(cnn_feat)
x = BatchNormalization()(x)
x = Dense(units = 8, activation=hidden_act_fun)(x)
x = BatchNormalization()(x)
dense = Dense(units= 1, activation=final_act_fun)(x)

# Compile Model
p_phase_picker = Model(input_trace, dense, name = name)
p_phase_picker.compile(optimizer = optimizer, loss = loss_type)
p_phase_picker.summary()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1800, 3)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1800, 32)          608       
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 900, 32)           0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 900, 64)           12352     
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 450, 64)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                921632    
_________________________________________________________________
batch_normalization_1 (Batch (None, 32)                128       
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 264       
_________________________________________________________________
batch_normalization_2 (Batch (None, 8)                 32        
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 935,025
Trainable params: 934,945
Non-trainable params: 80
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name=&#39;train_model&#39;&gt;Training the Model&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;With our data read in and our model architecture defined, we are now ready to run our baseline convolutional neural network.  In Keras this amounts to giving our compiled model the training data set and its associated labels, the number of epochs and batch size we want, and the validation set as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Train Model
history = p_phase_picker.fit(x = x_train,
                            y = y_train,
                            epochs= epochs,
                            batch_size=batch_size,
                            validation_data=(x_val, y_val))

# Keep track of the last loss values (for easy comparison later)
train_loss = history.history[&#39;loss&#39;]
last_train_loss_value = train_loss[len(train_loss)-1]
val_loss = history.history[&#39;val_loss&#39;]
last_val_loss_value = val_loss[len(val_loss) - 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Epoch 1/400
5725/5725 [==============================] - 4s 780us/step - loss: 367974.3419 - val_loss: 370470.2668
Epoch 2/400
5725/5725 [==============================] - 4s 632us/step - loss: 367804.4836 - val_loss: 371916.8610
Epoch 3/400
5725/5725 [==============================] - 4s 624us/step - loss: 367594.1336 - val_loss: 370046.7134
Epoch 4/400
5725/5725 [==============================] - 4s 635us/step - loss: 367357.8737 - val_loss: 370197.6924
Epoch 5/400
5725/5725 [==============================] - 4s 647us/step - loss: 367116.8329 - val_loss: 372166.2775
Epoch 6/400
5725/5725 [==============================] - 4s 645us/step - loss: 366859.2670 - val_loss: 371878.3604
Epoch 7/400
5725/5725 [==============================] - 4s 651us/step - loss: 366575.9700 - val_loss: 368855.4593
Epoch 8/400
5725/5725 [==============================] - 4s 644us/step - loss: 366252.4366 - val_loss: 365949.0822
Epoch 9/400
5725/5725 [==============================] - 4s 643us/step - loss: 365918.8507 - val_loss: 353128.8180
Epoch 10/400
5725/5725 [==============================] - 4s 640us/step - loss: 365568.8157 - val_loss: 360134.3884
Epoch 11/400
5725/5725 [==============================] - 4s 643us/step - loss: 365160.4010 - val_loss: 362235.5229
Epoch 12/400
5725/5725 [==============================] - 4s 641us/step - loss: 364738.2535 - val_loss: 352015.1630
Epoch 13/400
5725/5725 [==============================] - 4s 641us/step - loss: 364275.2614 - val_loss: 354300.4198
Epoch 14/400
5725/5725 [==============================] - 4s 634us/step - loss: 363814.7165 - val_loss: 347660.5830
Epoch 15/400
5725/5725 [==============================] - 4s 636us/step - loss: 363339.9869 - val_loss: 357162.0319
Epoch 16/400
5725/5725 [==============================] - 4s 640us/step - loss: 362818.9280 - val_loss: 359878.0607
Epoch 17/400
5725/5725 [==============================] - 4s 637us/step - loss: 362306.8130 - val_loss: 348699.6071
Epoch 18/400
5725/5725 [==============================] - 4s 640us/step - loss: 361731.6002 - val_loss: 349205.2539
Epoch 19/400
5725/5725 [==============================] - 4s 636us/step - loss: 361150.4833 - val_loss: 351060.9939
Epoch 20/400
5725/5725 [==============================] - 4s 635us/step - loss: 360559.7594 - val_loss: 340123.2790
.
.
.
Epoch 385/400
5725/5725 [==============================] - 4s 637us/step - loss: 6572.9224 - val_loss: 18183.6428
Epoch 386/400
5725/5725 [==============================] - 4s 635us/step - loss: 6540.7187 - val_loss: 18267.0756
Epoch 387/400
5725/5725 [==============================] - 4s 635us/step - loss: 6536.7624 - val_loss: 18081.5158
Epoch 388/400
5725/5725 [==============================] - 4s 634us/step - loss: 6536.4518 - val_loss: 18305.2634
Epoch 389/400
5725/5725 [==============================] - 4s 637us/step - loss: 6549.2467 - val_loss: 18346.6905
Epoch 390/400
5725/5725 [==============================] - 4s 639us/step - loss: 6537.4118 - val_loss: 18083.2445
Epoch 391/400
5725/5725 [==============================] - 4s 635us/step - loss: 6526.0619 - val_loss: 18387.9119
Epoch 392/400
5725/5725 [==============================] - 4s 639us/step - loss: 6508.7915 - val_loss: 18279.9480
Epoch 393/400
5725/5725 [==============================] - 4s 633us/step - loss: 6522.6132 - val_loss: 18310.2310
Epoch 394/400
5725/5725 [==============================] - 4s 635us/step - loss: 6518.6792 - val_loss: 18221.4595
Epoch 395/400
5725/5725 [==============================] - 4s 636us/step - loss: 6532.9096 - val_loss: 18169.3012
Epoch 396/400
5725/5725 [==============================] - 4s 638us/step - loss: 6525.6210 - val_loss: 18193.7779
Epoch 397/400
5725/5725 [==============================] - 4s 636us/step - loss: 6519.6705 - val_loss: 18258.7685
Epoch 398/400
5725/5725 [==============================] - 4s 632us/step - loss: 6517.0802 - val_loss: 18250.5715
Epoch 399/400
5725/5725 [==============================] - 4s 633us/step - loss: 6516.5765 - val_loss: 18335.3135
Epoch 400/400
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#39;interpreting_results&#39;&gt;Interpreting the Results&lt;/a&gt;&lt;/h2&gt;  

&lt;p&gt;What does the above tell us? For each epoch the Keras API prints:&lt;/p&gt;

&lt;p&gt;1) Computation time&lt;br /&gt;
2) The loss from the training and validation data sets.&lt;/p&gt;

&lt;p&gt;The second point here is worth spending some time thinking about. Remember that the overall objective is to create an algorithm which learns from the data we give it. i.e. we want our algorithm to generalize to data it has never seen before.  We should expect, therefore, that the training loss decreases for every epoch. Does this happen in our case? Let&amp;rsquo;s plot the training and validation loss curves (sometimes called &amp;lsquo;learning curves&amp;rsquo;) to help us understand a little more of how well our deep neural network performed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Validation loss curves #
fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (10,6))
axes.plot(history.history[&#39;loss&#39;])
axes.plot(history.history[&#39;val_loss&#39;])
axes.set_title(&#39;Model Loss&#39;)
axes.set_ylabel(&#39;loss&#39;)
axes.set_xlabel(&#39;epoch&#39;)
axes.legend([&#39;Train&#39;, &#39;Validation&#39;], loc=&#39;upper left&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img style=&#34;float:left&#34; src=&#34;./img/model_loss.png&#34;  &gt;
&lt;b&gt;Figure:&lt;/b&gt; Learning curve results from training 1D convolutional neural network with the above-mentioned hyper parameters. Red curve depicts loss from training set, blue curve depicts loss from validation set.&lt;/p&gt;

&lt;p&gt;The red and blue curves show the loss (sometimes called &amp;lsquo;cost&amp;rsquo;) per epoch on the training and validation set, respectively.  As expected, the neural network performs poorly at the onset of training(at this point the model is probably randomly guessing where the first phase is) and gradually improves with epoch. During training the neural network is learning directly from the training set, so the prediction error (loss/cost) is lower than that of the validation training set.&lt;/p&gt;

&lt;p&gt;We stopped training around epoch &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;400&lt;/span&gt; because at this point it would seem our neural network is no longer learning/improving its ability to make predictions. Also, we don&amp;rsquo;t want to let the neural network run too long, else the neural network might begin to over fit.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#39;visualize_results&#39;&gt;Visualize the Results&lt;/a&gt;&lt;/h2&gt;  

&lt;p&gt;I don&amp;rsquo;t know about you, but most of the tutorials I come across normally end here. Meaning, they show a loss curve from training and call it a day. I am a visual person, so I want to see what the output of my model gave me. Sure, these learning curves tell me that, to a first order that my neural network is learning to pick the first arrival. But, how does this look compared to the pick made by a human being? Let&amp;rsquo;s look at some earthquakes.&lt;/p&gt;

&lt;p&gt;Below I have plotted two randomly (using Numpy&amp;rsquo;s &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;rand.randint()&lt;/span&gt; function) chosen waveforms from our validation set.  The red vertical line is the pick made by a humanoid. The purple line is the pick made by our CNN.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def read_results(file_name):
    file_npz = np.load(file_name)
    
    read_list = []
    for item in file_npz:
        read_list.append(file_npz[item])
    
    return np.array(read_list)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;directory = &#39;./data_directory&#39;

## Read in earthquake waveforms
file = &amp;quot;waves4picking.npz&amp;quot;
file_path = os.path.join(directory, file)
waves_array = read_results(file_path)
# Reshape from (1, 1431, 1800, 3) to (1431, 1800, 3)
waves_array = np.reshape(waves_array, newshape=(waves_array.shape[1], waves_array.shape[2], waves_array.shape[3]))


## Read picks made by people
file2 = &amp;quot;spicks_used.npz&amp;quot;
file_path2 = os.path.join(directory, file2)
ppick_array = read_results(file_path2)
ppick_array = np.reshape(ppick_array, newshape=(ppick_array.shape[1])) # Reshape from (1, 1431) to (1431,)


## Picks made by machine learning
file3 = &#39;ml_spicks.npz&#39;
file_path3 = os.path.join(directory, file3)
ml_ppicks = read_results(file_path3)
ml_ppicks = np.reshape(ml_ppicks, newshape=(ml_ppicks.shape[1]))    # Reshape from (1, 1431) to (1431,)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Waveform specs.
sampling_rate = 20.0
npts = 1800 
delta = 0.05
time = np.arange( 0, npts / sampling_rate, delta)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Let&#39;s select waveforms, and their associated picks, randomly
tr = np.random.randint(0, waves_array.shape[0])
tr1 = np.random.randint(0, waves_array.shape[0])

rows = 2
fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(16,8))
axes[0].set_title(&amp;quot;Trace {}&amp;quot;.format(tr))
axes[0].plot(time, waves_array[tr, :, 0], color = &#39;black&#39;)
axes[0].axvline(ppick_array[tr] / sampling_rate, color = &#39;red&#39;, label = &amp;quot;p_pick manual&amp;quot;)
axes[0].axvline(ml_ppicks[tr] / sampling_rate, color = &#39;purple&#39; , label = &#39;ml_pick&#39;)

axes[1].set_title(&amp;quot;Trace {}&amp;quot;.format(tr1))
axes[1].plot(time, waves_array[tr1, :, 0], color = &#39;black&#39;)
axes[1].axvline(ppick_array[tr1] / sampling_rate, color = &#39;red&#39;, label = &amp;quot;p_pick manual&amp;quot;)
axes[1].axvline(ml_ppicks[tr1] / sampling_rate, color = &#39;purple&#39; , label = &#39;ml_pick&#39;)
axes[1].set_xlabel(&amp;quot;Time [s]&amp;quot;)

for i in range(rows):
    axes[i].set_ylabel(&#39;Norm. Amp.&#39;)
    axes[i].legend()
    
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src = &#34;./img/output_27_0.png&#34;&gt;
&lt;b&gt;Figure:&lt;/b&gt; Two randomly chosen earthquake seismic records from the training set. The red vertical line is the manually selected phase arrival. The purple line depicts the phase pick made by the machine learning algorithm after training.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
You&amp;rsquo;ll notice that, depending on the waveform, our CNN has varying levels of success in picking the first arrival.  This makes sense given that so far we have only run a baseline model; there is still plenty of refining and polishing that has to be done before we can expect too much from our neural network.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s left do? We&amp;rsquo;ll explore this in the next section.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#39;whats_next&#39;&gt;What&#39;s Next?&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s loads to do before we can call this model satisfactory. For a start, we should try to get more data. The model results shown above only used ~10,000 waveforms, which is a bit on the small side for a deep neural network. It might be instructive to try to double or triple this and see if our loss curves improve.&lt;/p&gt;

&lt;p&gt;We could also play with the complexity of our model. At the moment we only have two 1D convolutional layers. Perhaps the model will perform better with more or larger filter sizes? (&lt;b&gt;Warning:&lt;/b&gt; it is best practice to start small before jumping into larger models!)&lt;/p&gt;

&lt;p&gt;One could and should explore the batch sizes and/or using a different optimization method.&lt;/p&gt;

&lt;p&gt;We could and should shift the window of where our seismic waveform is centered. Not only might this make our neural network more robust, it will increase how much training data we have (i.e. data augmentation).&lt;/p&gt;

&lt;p&gt;Once we have reached a point where we are satisfied with how our model is performing we will need to run this on a &lt;b&gt;test set&lt;/b&gt;. In other words, we need to run this on a data set which the convolutional neural network has never seen before. To do this, simply leave a fraction (maybe 1/10th) of your entire data set and save it for later use. Once you have your model parameters, simply load them in and run it on your test set. Keras makes this very easy to do and I&amp;rsquo;ll go into detail in a future post of how to do this.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#39;conclusion&#39;&gt;Conclusion&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;In this tutorial we covered how to &lt;b&gt;compile&lt;/b&gt;, &lt;b&gt;train&lt;/b&gt;, and make a surface-level &lt;b&gt;evaluation&lt;/b&gt; of a baseline convolutional neural network.  In the first part of the tutorial we learned how to frame our problem, download data, process it, and save it into a file format from which we could use for training our convolutional neural network.&lt;/p&gt;

&lt;p&gt;Identifying the first arriving seismic wave generated by an earthquake is a critical component of earthquake early warning and it is a topic that is of continued interest from both a scientific and public safety point of view. As of writing this post, earthquake early warning has recently received more funding to support operations, improve existing seismic stations, and expand the current earthquake early warning system on the West Coast.&lt;/p&gt;

&lt;p&gt;While there exists non-machine learning earthquake detection systems, it remains to be seen if deep neural networks can not only classify and detect earthquakes, but do so more accurately and faster than current detection algorithms which do not use DNN.&lt;/p&gt;

&lt;p&gt;You can find the source code to this tutorial on my &lt;a href =&#34;https://github.com/ngrayluna/P_Phase_Picker&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h3&gt;Suggested Reading Material&lt;/h3&gt;  

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Géron, A. (2017). Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems. O&amp;rsquo;Reilly UK Ltd.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stanford CS class CS231n: &lt;a href=&#34;http://cs231n.github.io/&#34; target=&#34;_blank&#34;&gt;Convolutional Neural Networks for Visual Recognition&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ackermann, Nils. &amp;ldquo;Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences&amp;rdquo; &lt;i&gt;Medium&lt;/i&gt;, 04 September 2018, &lt;a href=&#34;https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf&#34; target=&#34;_blank&#34;&gt;https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Training a Recurrent Neural Network Using Keras</title>
      <link>https://ngrayluna.github.io/post/rnn_wkeras/</link>
      <pubDate>Thu, 05 Sep 2019 14:00:31 -0700</pubDate>
      <guid>https://ngrayluna.github.io/post/rnn_wkeras/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;./img/Neurons-Network_T.jpg&#34;&gt;&lt;/p&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#frame_the_problem&#34;&gt;Frame the Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#retrieve_data&#34;&gt;Get the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#explore_data&#34;&gt;Explore the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prepare_data&#34;&gt;Prepare the Data for Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#non_machine&#34;&gt;A Non Machine Learning Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#machine_baseline&#34;&gt;Machine Learning Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rnn_wKeras&#34;&gt;Building a RNN with Keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rnn_baseline&#34;&gt;A RNN Baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;*extra&#34; target=&#34;_blank&#34;&gt;Extra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The attractive nature of RNNs comes froms our desire to work with data that has some form of statistical dependency on previous and future outputs. This can take the form of text, such as learning how words in a sentence should flow. It can take the form of timeseries data, such as seismograms, just to name a few. Recurrent neural networks processes sequences by iterating through the sequence of elements and maintaining a state containing information relative to what it has seen so far. [Chollet, F. (2017)]&lt;/p&gt;

&lt;p&gt;With our basic understanding of RNNs, it&amp;rsquo;s time to dive into a small examples using real timeseries data.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s remind ourselves what the general machine learning workflow is so that we don&amp;rsquo;t get lost:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Frame the Problem&lt;/b&gt; &amp;ndash;&amp;gt; &lt;b&gt;Get the Data&lt;/b&gt; &amp;ndash;&amp;gt; &lt;b&gt;Explore the Data&lt;/b&gt; &amp;ndash;&amp;gt; &lt;b&gt;Prepare the Data&lt;/b&gt; &amp;ndash;&amp;gt; &lt;b&gt;Short-List Promising Models&lt;/b&gt; &amp;ndash;&amp;gt; &lt;b&gt;Fine-Tune the System&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We won&amp;rsquo;t have time to go through each of these steps in detail, but I encourage you to read Chapter 2 from Géron&amp;rsquo;s book [see Suggested Reading below].&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Run this first
import os
import numpy as np
import matplotlib.pyplot as plt

%matplotlib inline

from keras.models import Sequential
from keras import layers
from keras.optimizers import RMSprop
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#34;frame_the_problem&#34;&gt;Frame the Problem&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;We want to know if it is possible to predict the temperature in the future? For a given day, we want to look back some days (i.e. time steps) and use said information to predict the weather in the future.  We&amp;rsquo;ll use the following variables to contrain what we mean by &amp;lsquo;past&amp;rsquo; and &amp;lsquo;future&amp;rsquo;:&lt;/p&gt;

&lt;p&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;look back&lt;/span&gt; - number of timesteps to look back from&lt;br /&gt;
&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;delay&lt;/span&gt;  - number of timesteps in the future&lt;br /&gt;
&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;steps&lt;/span&gt;  -  our sample rate&lt;/p&gt;

&lt;p&gt;In our case that we will set &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;look back&lt;/span&gt; = 1440 (1 day consists of 1440 minutes), &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;step&lt;/span&gt; = 6 (one data point per hour), and &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;delay&lt;/span&gt; = 1440 (one day in the future).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# How many timesteps back the input data should go.
# Note: 1 day is 1440 minutes
lookback = 1440

# The period, in timesteps, at which you sample data. Set to 6 in
# order to draw one data point every hour.
step = 6

# How many timesteps in the future the target should be.
delay = 1440
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#39;retrieve_data&#39;&gt;Get the Data&lt;/a&gt;&lt;/h2&gt;  

&lt;p&gt;Our data set is a timeseries from the Weather Station at the Max Planck Institute for &lt;a href=&#34;https://www.bgc-jena.mpg.de/wetter/&#34; target=&#34;_blank&#34;&gt;Biogeochemistry in Jena, Germany&lt;/a&gt;.  Lucky for us, this is already in a format we can quickly and easily work with. We just need to read it in, store it in a workable format, and do some very basic data processing.&lt;/p&gt;

&lt;p&gt;Download the data and store it in your working directory. Once you have done that, execute this block:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data_dir = &#39;./&#39;
fname = os.path.join(data_dir, &#39;jena_climate_2009_2016.csv&#39;)

f = open(fname)
data = f.read()
f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since we are working with a .csv file we first need to read it in, and then beat it into something we can work with. Depending on how large your data set is (both row and column-wise) you might want to invest learning using &lt;a href=&#34;https://pandas.pydata.org/&#34; target=&#34;_blank&#34;&gt;Pandas&lt;/a&gt;. It is a library that allows for easy data manipulation and works great for .csv, .xlsx, and .txt sort of data file types.&lt;/p&gt;

&lt;p&gt;We only have a few thousand samples (420551, to be exact), so we will just use some build-in Python functions:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;lines = data.split(&#39;\n&#39;)
header = lines[0].split(&#39;,&#39;)
lines = lines[1:]

print(&amp;quot;Our header information: &amp;quot;,&#39;\n&#39;)
print(header)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Our header information:  

[&#39;&amp;quot;Date Time&amp;quot;&#39;, &#39;&amp;quot;p (mbar)&amp;quot;&#39;, &#39;&amp;quot;T (degC)&amp;quot;&#39;, &#39;&amp;quot;Tpot (K)&amp;quot;&#39;, &#39;&amp;quot;Tdew (degC)&amp;quot;&#39;, &#39;&amp;quot;rh (%)&amp;quot;&#39;, &#39;&amp;quot;VPmax (mbar)&amp;quot;&#39;, &#39;&amp;quot;VPact (mbar)&amp;quot;&#39;, &#39;&amp;quot;VPdef (mbar)&amp;quot;&#39;, &#39;&amp;quot;sh (g/kg)&amp;quot;&#39;, &#39;&amp;quot;H2OC (mmol/mol)&amp;quot;&#39;, &#39;&amp;quot;rho (g/m**3)&amp;quot;&#39;, &#39;&amp;quot;wv (m/s)&amp;quot;&#39;, &#39;&amp;quot;max. wv (m/s)&amp;quot;&#39;, &#39;&amp;quot;wd (deg)&amp;quot;&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that we seperated the header titles and stored them in the &amp;ldquo;header&amp;rdquo; variable. We also made sure to remove the first column in our floats which contained the &amp;ldquo;Date Time&amp;rdquo; values. [Line #3]&lt;/p&gt;

&lt;p&gt;Now that we have read our data in, let&amp;rsquo;s parse it and store it into a Numpy array so we can easily access the float values later:&lt;/p&gt;

&lt;h3&gt;Parse the Data into a Numpy Array&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;float_data = np.zeros((len(lines), len(header) - 1))
for i, line in enumerate(lines):
    values = [float(x) for x in line.split(&#39;,&#39;)[1:]]
    float_data[i, :] = values
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I like to do sanity checks along the way, so let&amp;rsquo;s make sure our dimensions make sense:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(float_data.shape)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(420551, 14)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We have 420551 time steps (done every 10 minutes), with 14 columns/features. I.e. we created a 2D tensor with dimensions: (# of samples, features).&lt;/p&gt;

&lt;p&gt;Great. So far so good.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name=&#39;explore_data&#39;&gt;Explore the Data&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s always a good idea to get a sense of what our data looks like. &lt;b&gt;Data exploration&lt;/b&gt; is a necessary step to get a broad sense of what kind of data you are working with and to get an overall &amp;lsquo;feel&amp;rsquo; for the data. Depending on the data type, you might want to make histograms or scatter plots for each numerical attribute.  You could also compute some basic statistical attributes of your data set such as the mean, standard deviations, minimum and maximum values, and percentiles. (You can take advantage of &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt;&amp;rsquo; built-in function for quick results).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do a VERY mild peek at our data. Specifically, let&amp;rsquo;s plot the temperature and see how it behaves over time:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;temp = float_data[:, 1]  # temperature (in degrees Celsius)

fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(14,5))
ax.plot(range(len(temp)), temp)
ax.set_ylabel(&#39;Degrees [C]&#39;)
ax.set_xlabel(&#39;Time [min]&#39;)

plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./img/output_18_0.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;As one might expect (or hope to expect), we see a periodic temperature pattern over the years.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name=&#39;prepare_data&#39;&gt;Prepare the Data for Training&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Depending on what your data set is, you might consider using transformation Pipelines for preprocessing your data.
In our case, we want to take care of the fact our data has different scales. Neural networks don&amp;rsquo;t perform well if their scales are dramatically different. No problem, we&amp;rsquo;ll just normalize our timeseries.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; We only do this to our training data (our first 200000 time steps). So only compute and modify these sampels:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mean = float_data[:200000].mean(axis=0)
float_data -= mean
std = float_data[:200000].std(axis=0)
float_data /= std
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Split Data into Training, Validation, and Testing&lt;/h2&gt;

&lt;p&gt;Always split your data set into a &lt;b&gt;trainig&lt;/b&gt;, &lt;b&gt;validation&lt;/b&gt;, and a &lt;b&gt;test&lt;/b&gt; set.  As a rule of thumb: you&amp;rsquo;ll want to split it such that you leave 20% of your data for testing and keep the rest as your training and validation set.  The bottom snippet of code might look confusing at first, but all it is is a Python Generator for creating the above mentioned data sets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Generator yields a tuple (samples, targets), where samples is one batch 
# of input data and targets is the corresponding array of
# target temperatures.
def generator(data, lookback, delay, min_index, max_index,\
              shuffle=False, batch_size=128, step=6):
    &amp;quot;&amp;quot;&amp;quot;
    Parameters
    ----------
    data: array, dtype = floats or integers
        array containing our data 
    
    lookback: integer
        number of timesteps to take backward from current index
    
    delay: integer
        number of timesteps to take forward from current index
    
    min_index: integer
        index value used to set lower bound in data array
        e.g. array_test[min_index:]
    
    max_index: integer
        index value used to cap data array
        e.g. array_test[:max_index]
    
    shuffle: boolean
        used to determine whether or not to shuffle data or
        keep in given order
    
    batch_size: integer
        how many sequences to give per epoch
        
    step: integer
        The period, in timesteps, we sample data with
    
    Returns:
    -------
    samples: array, dtype = float or int
        a single batch of input data 
    
    targets: array, dtype = float, int, or str
        a single array of target values (in this case temperature)
    &amp;quot;&amp;quot;&amp;quot;
    
    if max_index is None:
        max_index = len(data) - delay - 1
    i = min_index + lookback
    while 1:
        if shuffle:
            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)
        else:
            if i + batch_size &amp;gt;= max_index:
                i = min_index + lookback
            rows = np.arange(i, min(i + batch_size, max_index))
            i += len(rows)
        samples = np.zeros((len(rows),lookback // step,data.shape[-1]))
        targets = np.zeros((len(rows),))
        for j, row in enumerate(rows):
            # range(start, end, steps)
            # First value you start from a random time spot, then go back one day.
            # i.e. start: random_time - day, end on random_time, take steps of one hour
            # Want one sample every hour) --&amp;gt; 1440 minutes / 60 minutes = 240 timesteps
            indices = range(rows[j] - lookback, rows[j], step)
            samples[j] = data[indices]
            samples[j] = data[indices]
        yield samples, targets
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Going back to our problem, we said we wanted to use data going back a certain amount of time (data points in our timeseries) to predict the weather in the future (defined by the variable &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;delay&lt;/span&gt;). Let&amp;rsquo;s create the data sets we need to feed our recurrent neural network:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# How many timesteps back the input data should go.
# Note: 1 day is 1440 minutes
lookback = 1440

# The period, in timesteps, at which you sample data. Set to 6 in
# order to draw one data point every hour.
step = 6

# How many timesteps in the future the target should be.
delay = 144

# The number of samples per batch.
batch_size = 128

# Generate data
train_gen = generator(float_data, lookback=lookback, delay=delay,\
                      min_index=0, max_index=200000, shuffle=True,\
                      step=step, batch_size=batch_size)

val_gen = generator(float_data, lookback=lookback, delay=delay,\
                    min_index=200001, max_index=300000, step=step,\
                    batch_size=batch_size)

test_gen = generator(float_data, lookback=lookback, delay=delay,\
                     min_index=300001, max_index=None, step=step,\
                     batch_size=batch_size)

# How many steps to draw from val_gen in order to see the entire validation set.
val_steps = (300000 - 200001 - lookback)

# How many steps to draw from test_gen in order to see the entire test set.
test_steps = (len(float_data) - 300001 - lookback)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#39;non_machine&#39;&gt;Establishing a Common Sense Non Machine Learning Baseline&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Before running this model you want to establish a baseline. Baslines are useful for a couple of reasons: first, it gives you something to compare the performance of your machine learning algorithm with. If your computationally heavy, machine learning algorithm does not perform better than a simple MAE, well&amp;hellip;then there&amp;rsquo;s not really a point to use a machine learning algorithm; The second reason for creating a baseline: they serve as a sanity check.&lt;/p&gt;

&lt;p&gt;Since we are curious about predicting the temperature in the future, a common sense non machine learning baseline could involve using temperature from the last 24 hours to say something about right now.&lt;/p&gt;

&lt;p&gt;One of doing this could be using an MAE. Here is a code snippet example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.mean(np.abs(preds - targets))
And the associated code snippet for the entire loop:  
batch_maes = []

for step in range(val_steps):
    samples, targets = next(val_gen)
    preds = samples[:, -1, 1]
    mae = np.mean(np.abs(preds - targets))
    batch_maes.append(mae)
    
print(np.mean(batch_maes))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you compute the standard deviation of the temperature and run the code snippet above, you&amp;rsquo;ll be get an MAE = 0.29  . This number obviously doesn&amp;rsquo;t make any intuitive sense because our data was normalized to be centered at 0 and have a standard deviation of 1.  Translating this into something more understandable, we have an absolute error of:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;0.29 * &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;temperature_std&lt;/span&gt; = 2.57°C&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Which is not terrible, but it&amp;rsquo;s not great. We hope that our machine learning approach will better. Let&amp;rsquo;s find out.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#39;machine_baseline&#39;&gt;A Basic Machine Learning Approach&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I would suggest trying to execute the next block but then interrupting the kernal once you get a flavor of how long it&amp;rsquo;ll take to run.&lt;/p&gt;

&lt;p&gt;Because of this shortcoming, I&amp;rsquo;ve provided screen shots for the remaining part of the notebook of what will show up if you were to run this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()

# input shape: (240, 14)
model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))
model.add(layers.Dense(32, activation=&#39;relu&#39;))
model.add(layers.Dense(1))

model.compile(optimizer=RMSprop(), loss=&#39;mae&#39;)
history = model.fit_generator(train_gen,
                              steps_per_epoch=100,
                              epochs=20,
                              validation_data=val_gen,
                              validation_steps=val_steps)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./img/prog_bar_basicML.png&#34;  &gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Interpreting the Results of a Basic Machine Learning Algorithm&lt;/h2&gt;  

&lt;p&gt;Let&amp;rsquo;s plot the loss curves for both the training and validation data sets:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(len(loss))

plt.figure()

plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.legend()

plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./img/newfirst_ml_approach.png&#34; width=&#34;410&#34; &gt;&lt;/p&gt;

&lt;p&gt;What do we see? On the x-axis we one again have epochs and the y-axis we see the output of our loss function, the mean absolute error. Looking at the training loss we note that with increasing epoch our loss is going down. i.e. the function we are trying to minimize is actually being minimized.&lt;/p&gt;

&lt;p&gt;But, we can&amp;rsquo;t celebrate just yet. Arguably more important is understanding our validation loss. We would hope that it too would have smaller loss values with each iteration. Instead, we see that our validation loss is increasing after iteration 5.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;&lt;a name =&#39;extra&#39;&gt;A Blurb on the Hypothesis Space&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Interesing enough, our &amp;lsquo;common sense&amp;rsquo; approach earlier gave us a MAE of 0.29. Which, comparing to our results, is actually better. Why is this? More specifically, why didn&amp;rsquo;t we find the same hypothesis used for the common sense approach?&lt;/p&gt;

&lt;p&gt;Remember that the overall objective of a machine learning algorithm is to find the mapping function/hypothesis between an independent variable X and a dependent variable y such that it best minimizes the cost function. The hypothesis space, where our mapping function lives, of our machine learning network is the space of all possible 2-layer networks with the configuration that we defined. So, it may be that the space we just defined with our machine learning algorithm doesn&amp;rsquo;t actually have the hypothesis we originally found.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now move on to the main purpose of this notebook, using a recurrent neural netork.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Building a RNN with Keras&lt;/h2&gt;

&lt;p&gt;The simplest RNN we can use with Keras is literally called&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;model.add(SimpleRNN( ))&lt;/span&gt;  &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keras.models import Sequential
from keras import layers 
from keras.layers import Embedding, Dense, SimpleRNN

model = Sequential()
model.add(SimpleRNN(10, input_shape=(3, 1)))
model.add(Dense(1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at this line by line:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Line 5:&lt;/b&gt; Defined our model architect using a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Sequential&lt;/span&gt; class.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Line 6:&lt;/b&gt; Added our RNN layer (which also serves as our input layer).&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Line 7:&lt;/b&gt; Added a fully connected (i.e. Dense) layer as our output layer.&lt;/p&gt;

&lt;p&gt;The &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;model.summary()&lt;/span&gt; function is a convenient way of checking how our deep neural network textually looks like. It provides key information of our architecture such as:&lt;/p&gt;

&lt;p&gt;the &lt;b&gt;layer type&lt;/b&gt; and the order of the layers from input (first row) to output (bottom row before the &amp;lsquo;=&amp;rsquo;);&lt;br /&gt;
the &lt;b&gt;shape of the tensor&lt;/b&gt; for each output (and thus, what is going into the next layer);&lt;br /&gt;
and the &lt;b&gt;number of weights&lt;/b&gt; (here labeled &amp;lsquo;parameters&amp;rsquo;) per layer along with a summary of the total number of weights.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.summary()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 10)                120       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 11        
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What do we see? The first line is our header&lt;/p&gt;

&lt;p&gt;&lt;center&gt;[ &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Layer(type)&lt;/span&gt;, &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt; Output Shape,&lt;/span&gt;, and &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt; Param # &lt;/span&gt;]&lt;/center&gt;&lt;br /&gt;
Where &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Output Shape&lt;/span&gt; is the shape of the tensor that is leaving our first layer (&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;SimpleRNN&lt;/span&gt;) and going into the next layer &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense&lt;/span&gt; (i.e. a fully connected layer).&lt;/p&gt;

&lt;p&gt;In the next line We see that we have an output shape of (None, 10) and 120 Parameters:&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;simple_rnn_1 (SimpleRNN) (None, 10) 120 &lt;/span&gt;  &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;What does this mean? When we wrote line 6:&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;SimpleRNN(10, input_shape=(3, 1))&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;We specified that we had 10 weights (parameters) and input shape of (3,1). The 3 here means we have 3 sequences(e.g. three timeseries points) we want to input and 1 featuere (e.g. Temperature).&lt;/p&gt;

&lt;p&gt;The formula for the number of parameters/weights:&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Parameters&lt;/span&gt; = num_weights x num_weights + num_features x num_weights + biases&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt; = $10 * 10 + 1 * 10 + 10 = 120$&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Note: Full explaination of the parameters below&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Finally, we have our output layer. In this example we defined it as a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense&lt;/span&gt; layer:&lt;br /&gt;
&lt;br&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense(1)&lt;/span&gt;  &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So this last &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense&lt;/span&gt; layer takes its input (&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;10&lt;/span&gt; (the output of the previous layer) and adds the bias to give us &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;11&lt;/span&gt; parameters/weights. Since we defined the dense layer as: &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense(1)&lt;/span&gt; we are telling our neural network that we want a single output.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#39;rnn_baseline&#39;&gt;A Recurrent Neural Network Baseline&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Just like in our previous notebook we&amp;rsquo;ll create our deep neural network by first defining our model architecture with Keras&amp;rsquo; &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Sequential class&lt;/span&gt;. We&amp;rsquo;ll make a key change in that instead of using a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;SimpleRNN&lt;/span&gt; we&amp;rsquo;ll use a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;GRU&lt;/span&gt; layer. I won&amp;rsquo;t go into the details here (if you are curious to learn more, I would suggest reading this &lt;a href=&#34;https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be&#34; target=&#34;_blank&#34;&gt;blog&lt;/a&gt; post) of what GRUs are for brevity. But basically, GRUs are a variation of our Recurrent Neural Network except that it handles the &lt;b&gt;vanishing gradient problem&lt;/b&gt;. The link to the paper describing this by Cho, et al. can be found below in the Suggested Reading section.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()
model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))
# Note that our output layer is defined to have a single value(i.e. a temperature)
model.add(layers.Dense(1))

model.compile(optimizer=RMSprop(), loss=&#39;mae&#39;)
history = model.fit_generator(train_gen,
                              steps_per_epoch=500,
                              epochs=20,
                              validation_data=val_gen,
                              validation_steps=val_steps)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./img/epochs_run.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;What does the above show us? For each epoch Keras is printing out:&lt;/p&gt;

&lt;p&gt;1) How long it took (e.g. 10 seconds in this case)&lt;br /&gt;
2) The loss from the training and validation data sets.&lt;/p&gt;

&lt;p&gt;The second point here is worth spending some time thinking about. Remember that the overall objective is for us to create an algorithm which learns from the data we give it. i.e. we want our algorithm to generalize to data sets it has never seen before.  We should expect, therefore, that the training loss decreases for every epoch. Does this happen in our case? Plotting the training and validation loss will help us understand a litte more of how well our deep neural network did:&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Interpreting Results&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(len(loss))

plt.figure()

plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.legend()

plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./img/traning_val_plot.png&#34; style=&#34;width: 500px;&#34;&gt;&lt;/p&gt;

&lt;p&gt;What do we see? On the x-axis we once again have epochs and the y-axis we see the output of our loss function, the mean absolute error (which we defined when we compiled our RNN in code line 6) .  Looking at the training loss we note that with increasing epoch our loss is going down. i.e. the function we are trying to minimize is actually being minimized just like in our basic machine learning approach.&lt;/p&gt;

&lt;p&gt;Once again, however, our validation loss is increasing after a certain number of epochs.&lt;/p&gt;

&lt;p&gt;The fact our validation loss is increasing tells us two important aspects of our model: first, our algorithm did &lt;b&gt;not generalize well&lt;/b&gt; (i.e. it did not learn) and second, our algorithm was starting to &lt;b&gt;overfit&lt;/b&gt; on the training set.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s a bit disappointing&amp;hellip;but don&amp;rsquo;t fret! As it explained in Chollet&amp;rsquo;s &lt;i&gt;Deep Learning with Python&lt;/i&gt;[1], there are some tricks we can use to help stop and/or prevent overfitting; nameley, we can take advantage of &lt;b&gt;dropping out&lt;/b&gt;, using a &lt;b&gt;regularization&lt;/b&gt;, and &lt;b&gt;early stopping&lt;/b&gt;. I won&amp;rsquo;t go into the details here, but I would suggest reading &lt;a href=&#34;https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a&#34; target=&#34;_blank&#34;&gt;Skalski&amp;rsquo;s blog&lt;/a&gt; post for more information.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;More on How the Weights Are Computed for a RNN:&lt;/h2&gt;  

&lt;p&gt;From the output above we have 120 parameters. Why do we have 120 parameters?&lt;/p&gt;

&lt;p&gt;Remember, there are two things going on with our simple RNN: First you have the recurrent loop, where the state is fed recurrently into the model to generate the next step.  Weights for the recurrent step are:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;b&gt;recurrent_weights&lt;/b&gt; = num_units * num_units&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Second, there is a new input of your sequence at each step:
&lt;center&gt;&lt;b&gt;input_weights&lt;/b&gt; = num_features * num_units&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So now we have the weights, whats missing are the biases - for every unit one bias:
&lt;center&gt;&lt;b&gt;biases&lt;/b&gt; = num_units * 1&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;In our case we have that num_units = $10$ and num_features = $1$.&lt;/p&gt;

&lt;p&gt;Putting this altogether we have the following formula for the number of parameters/weights:&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Parameters&lt;/span&gt; = num_units x num_units + num_features x num_units + biases&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;b&gt;num_units&lt;/b&gt; is the number of weights in the RNN (&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;10&lt;/span&gt;) and &lt;b&gt;num_features&lt;/b&gt; is the number features of our input. (In thie case &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;1&lt;/span&gt;).&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Parameters&lt;/span&gt; = $10 * 10 + 1 * 10 + 10 = 120$&lt;/center&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h3&gt;About this Notebook&lt;/h3&gt;  

&lt;p&gt;The above example and code is from Ch.6 of Chollet&amp;rsquo;s &lt;i&gt;Deep Learning with Python&lt;/i&gt;[1]. Content was added for further clarification and readability.&lt;/p&gt;

&lt;h3&gt;Suggested Reading Material&lt;/h3&gt;  

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cho, et al. (2014), &amp;ldquo;Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation&amp;rdquo; &lt;i&gt;Association for Computational Linguistics&lt;/i&gt; &lt;a href=&#34;https://arxiv.org/pdf/1406.1078v3.pdf&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/pdf/1406.1078v3.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Géron, A. (2017). Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems. O&amp;rsquo;Reilly UK Ltd.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Karpath, Andrej. &amp;ldquo;The Unreasonable Effectiveness of Recurrent Neural Networks&amp;rdquo; &lt;i&gt;Andrej Karpathy blog&lt;/i&gt;, 24 March 2017, &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34; target=&#34;_blank&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kostadinov, Simeon. &amp;ldquo;Understanding GRU Networks&amp;rdquo; &lt;i&gt;Towards Data Science&lt;/i&gt;, 16 Dec. 2017, &lt;a href=&#34;https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be&#34; target=&#34;_blank&#34;&gt;https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Skalski, P. &amp;ldquo;Preventing Deep Neural Network from Overfitting&amp;rdquo; &lt;i&gt;Towards Data Science&lt;/i&gt;, 7 Sept. 2018 &lt;a href=&#34;https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a&#34; target=&#34;_blank&#34;&gt;https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Sources&lt;/h3&gt;  

&lt;p&gt;[1]Chollet, F. (2017). Deep Learning with Python. Manning Publications.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Code Your Own RNN with NumPy</title>
      <link>https://ngrayluna.github.io/post/rnn_wnumpy/</link>
      <pubDate>Mon, 01 Apr 2019 01:00:00 +0000</pubDate>
      <guid>https://ngrayluna.github.io/post/rnn_wnumpy/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;./img/Neurons-Network_T.jpg&#34;&gt;&lt;/p&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what_is_rnn&#34;&gt;What is a RNN &amp;amp; How Do They Work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rnn_wnumpy&#34;&gt;Writting a RNN with NumPy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dnn_wkeras&#34;&gt;Building a DNN with Keras&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;
&lt;h2&gt;&lt;a name = &#39;what_is_rnn&#39;&gt;What is a Recurrent Neural Network and How Do They Work?&lt;/a&gt;&lt;/h2&gt;&lt;/p&gt;

&lt;p&gt;Neural networks data as independent, isolated events. In other words, we don’t treat and/or make use of sequential data. Therefore, in order to process a time-series data (e.g. accelerometer data from a seismometer) or a sequence of events (e.g. text) you would have to feed the entire sequence to the neural network at once!&lt;/p&gt;

&lt;p&gt;This doesn’t make sense both on a computation-level and a human-level.  Think about it, as you read text you are storing a subset of this text in your short-term memory; you are keeping the sequence of words that are relevant for your understanding of the sentence.&lt;/p&gt;

&lt;p&gt;This is the idea behind Recurrent Neural Networks.  A &lt;i&gt;recurrent neural network&lt;/i&gt; (RNN) processes sequences by iterating through the sequence of elements and maintaining a &lt;i&gt;state&lt;/i&gt; containing information relative to what it has seen so far. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being dependent on the previous computations.&lt;/p&gt;

&lt;p&gt;In other words, data points are no longer processed in a single step. The network will loop over itself until it performs the same task on each element on the sequence.  The RNN will reset itself only when it reaches the final element.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s visualize this before going through an example. Below we see a typical RNN:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./img/rnn_diagram.png&#34;&gt;
&lt;b&gt;Left &lt;/b&gt;A single recurrent network, which is nothing more than a network with a loop. &lt;b&gt;Right &lt;/b&gt; The same RNN but &lt;i&gt;unrolled&lt;/i&gt; for visualization purposes.&lt;br /&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;$x_t$ and $s_t$ are the input and hidden state (both vectors), respectively, at time $t$. Matrices $U$, $V$, and $W$ are the parameters we want to learn from our data. And $o_t$ is the output vector computed using only the hidden state at time $t$.  The hidden state, $s_t$, is calculated based on the previous hidden state ($s_t-1$) and the input at the current step, $x_t$:&lt;/p&gt;

&lt;p&gt;$$s_t = f(U * x_t + W * s_t-1)$$&lt;/p&gt;

&lt;p&gt;i.e. $s_t$ kept information on what happened from all of the previous steps. It can be thought as a memory object. Note that, unlike other typical neural networks, recurrent neural networks reuse the same parameters (weights) $U$, $V$, and $W$ during the training process.  This makes sense since we are performing the same task on each element of the time sequence, $x_t$.&lt;/p&gt;

&lt;p&gt;Our activation function, $f$, is defined either as an $tanh$ or $ReLU$. For example, when $f$ is defined as $tanh$, our hidden state becomes:&lt;/p&gt;

&lt;p&gt;$$s_t = tanh(U * x_t + W * s_t-1)$$&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name =&#39;rnn_wnumpy&#39;&gt;Writting your own RNN using Numpy&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s do some programming to get a deep (pun intended) understanding of recurrent neural networks. To do this we will create a generic and simple RNN using Numpy.  The objective of this exercise it to understand on a basic level how an RNN operates. We will not worry about using real data for now. Instead, let&amp;rsquo;s create random data and feed this to an RNN. We will say that our input vector has $32$ input features (this is what goes into our input layer) and we will have an output vector with $64$ features.&lt;/p&gt;

&lt;p&gt;Below are the ingredients you&amp;rsquo;ll need and some psuedo code to get you started.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;RNN ingredients:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;1] Define the dimension of the input space. [This it the input layer of our neural network].&lt;/p&gt;

&lt;p&gt;2] Define the dimension of the output feature space [Output layer of our neural networt].&lt;/p&gt;

&lt;p&gt;3]  Generate random noise as our input ‘data’ [We just want to get an idea of HOW this works].&lt;br /&gt;
&lt;b&gt;Hint:&lt;/b&gt; Input vector should have dimensions (timesteps X input_features)&lt;/p&gt;

&lt;p&gt;4] Define an initial state, $s_{t}$, of the RNN.&lt;/p&gt;

&lt;p&gt;5] Create (random) weight matrices, $W$ and $U$.&lt;/p&gt;

&lt;p&gt;6] Create a for loop. that takes in the input with the current state (the previous output) to obtain the current output.&lt;br /&gt;
&lt;b&gt; Hint:&lt;/b&gt; Don&amp;rsquo;t forget about our activation function, $f$.&lt;/p&gt;

&lt;p&gt;7] Update the state for the next step.&lt;/p&gt;

&lt;p&gt;8] The final output should be a 2D tensor with dimensions (timesteps, output_features).&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;h2&gt;Pseudocode for RNN&lt;/h2&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# For the first timestep, the previous output isn’t defined; 
# Thus, our initial state is set to zero.
state_t = 0

#Iterates over sequnce elements
for input_t in input_sequence:
    output_t = f(input_t, state_t)
    # The previous output becomes the state for the next iteration.
    state_t  = output_t
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;h2&gt;How this would look like in Python:&lt;/h2&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;### Create fake data and store them as a tensor:
# Number of timesteps in the input sequence.
timesteps = 100

# Dimensionality of the input feature space
input_features = 32

# Dimensionality of the output feature space.
output_features = 64

# Input data is random for the sake of it
inputs = np.random.random((timesteps, input_features))


### RNN ###
# Initialize state: an all-zero vector
state_t = np.zeros((output_features))

# The RNN&#39;s parameters are two matrices W and U and a bias vector.
# Initialize random weight matrices
W = np.random.random((output_features, input_features))
U = np.random.random((output_features, output_features))
b = np.random.random((output_features,))

successive_outputs = []
for input_t in inputs:
    # Combines the input with the current state (the previous output)
    # to obtain the current output
    output_t = np.tanh( np.dot(W, input_t) + np.dot(U, state_t) + b )
    
    # Stores this output in a list
    successive_outputs.append(output_t)
    
    # Use for the next round:
    state_t = output_t

# The final output is a 2D tensor of shape (timesteps, output features)
final_output_sequence = np.concatenate(successive_outputs, axis = 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2&gt;&lt;a name = &#39;dnn_wkeras&#39;&gt;Building a DNN in Keras&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Before jumping in to defining an RNN using Keras, let&amp;rsquo;s remind ourselves what pieces we need to compile DNN using Keras&amp;rsquo; high-level neural network API. The ingredients are:&lt;/p&gt;

&lt;p&gt;&lt;b&gt; Define a model&lt;/b&gt;. In TensorFlow there are two ways to do this: first, by using a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Sequential&lt;/span&gt; class or second, with a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;functional API&lt;/span&gt; (which allows you to build arbritrary model structures).  Given that the most common neural network configuration is made up of linear stacks, you&amp;rsquo;ll most likely use the first method more often.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Define your DNN by stacking layers&lt;/b&gt; We start from  the input layer and &lt;i&gt;sequentially&lt;/i&gt; add more
layers: the hidden layers, and the output layer.(Hence, where the &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Class&lt;/span&gt; name came from).  Basically, the more layers you stack together, the more complex model you define (but at the potential expense of overfitting and/or long computation times!).&lt;/p&gt;

&lt;p&gt;One thing to keep in mind: each layer you define needs to be compatible with the next. In other words, each layer will only accept and return tensors of a certain shape.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Compile&lt;/b&gt; Before the training occurs, you need to define compile the model. To do this, use Keras&amp;rsquo; &lt;a href=&#34;https://keras.io/getting-started/sequential-model-guide/#compilation&#34; target=&#34;_blank&#34;&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;compile&lt;/span&gt;&lt;/a&gt; method.  This method takes in three arguments:&lt;br /&gt;
1) the &lt;a href=&#34;https://keras.io/optimizers/&#34; target=&#34;_blank&#34;&gt;optimizer&lt;/a&gt; - optimization algorithm (e.g. SGD, Adam, etc.); 2) the &lt;a href=&#34;https://keras.io/losses/&#34; target=&#34;_blank&#34;&gt;loss&lt;/a&gt; function the optimizer will try to minimize; and 3) a list of metrics (e.g. accuracy).&lt;/p&gt;

&lt;p&gt;And that&amp;rsquo;s it! The last step is to train the model using Keras&amp;rsquo; &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;fit&lt;/span&gt; function. More on this when we run our own RNN in the next notebook.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;With the above knowledge fresh in our memory we could replace our Numpy RNN (lines 17 - 39) with this ONE line:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;model.add(SimpleRNN( ))&lt;/span&gt;  &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keras.models import Sequential
from keras import layers 
from keras.layers import Embedding, Dense, SimpleRNN

model = Sequential()
model.add(SimpleRNN(10, input_shape=(3, 1)))
model.add(Dense(1))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Using TensorFlow backend.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at this line by line:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Line 5:&lt;/b&gt; Defined our model architect using a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Sequential&lt;/span&gt; class.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Line 6:&lt;/b&gt; Added our RNN layer (which also serves as our input layer).&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Line 7:&lt;/b&gt; Added a fully connected (i.e. Dense) layer as our output layer.&lt;/p&gt;

&lt;p&gt;The &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;model.summary()&lt;/span&gt; function is a convenient way of checking how our deep neural network textually looks like. It provides key information of our architecture such as:&lt;/p&gt;

&lt;p&gt;the &lt;b&gt;layer type&lt;/b&gt; and the order of the layers from input (first row) to output (bottom row before the &amp;lsquo;=&amp;rsquo;);&lt;br /&gt;
the &lt;b&gt;shape of the tensor&lt;/b&gt; for each output (and thus, what is going into the next layer);&lt;br /&gt;
and the &lt;b&gt;number of weights&lt;/b&gt; (here labeled &amp;lsquo;parameters&amp;rsquo;) per layer along with a summary of the total number of weights.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.summary()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 10)                120       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 11        
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What do we see? The first line is our header&lt;/p&gt;

&lt;p&gt;&lt;center&gt;[ &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Layer(type)&lt;/span&gt;, &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt; Output Shape,&lt;/span&gt;, and &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt; Param # &lt;/span&gt;]&lt;/center&gt;&lt;br /&gt;
Where &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Output Shape&lt;/span&gt; is the shape of the tensor that is leaving our first layer (&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;SimpleRNN&lt;/span&gt;) and going into the next layer &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense&lt;/span&gt; (i.e. a fully connected layer).&lt;/p&gt;

&lt;p&gt;In the next line We see that we have an output shape of (None, 10) and 120 Parameters:&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;simple_rnn_1 (SimpleRNN) (None, 10) 120 &lt;/span&gt;  &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;What does this mean? When we wrote line 6:&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;SimpleRNN(10, input_shape=(3, 1))&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;We specified that we had 10 weights (parameters) and input shape of (3,1). The 3 here means we have 3 sequences(e.g. three timeseries points) we want to input and 1 featuere (e.g. Temperature).&lt;/p&gt;

&lt;p&gt;OK, now to the weights.  From the output above we have 120 parameters. Why do we have 120 parameters?&lt;/p&gt;

&lt;p&gt;Remember, there are two things going on with our simple RNN: First you have the recurrent loop, where the state is fed recurrently into the model to generate the next step.  Weights for the recurrent step are:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;b&gt;recurrent_weights&lt;/b&gt; = num_units * num_units&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Second, there is a new input of your sequence at each step:
&lt;br&gt;&lt;center&gt;&lt;b&gt;input_weights&lt;/b&gt; = num_features * num_units&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So now we have the weights, whats missing are the biases - for every unit one bias:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;b&gt;biases&lt;/b&gt; = num_units * 1&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;In our case we have that num_units = $10$ and num_features = $1$.&lt;/p&gt;

&lt;p&gt;Putting this altogether we have the following formula for the number of parameters/weights:&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Parameters&lt;/span&gt; = num_units x num_units + num_features x num_units + biases&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;b&gt;num_units&lt;/b&gt; is the number of weights in the RNN (&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;10&lt;/span&gt;) and &lt;b&gt;num_features&lt;/b&gt; is the number features of our input. (In thie case &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;1&lt;/span&gt;).&lt;br /&gt;
&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Parameters&lt;/span&gt; = $10 * 10 + 1 * 10 + 10 = 120$&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Finally, we have our output layer. In this example we defined it as a &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense&lt;/span&gt; layer:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense(1)&lt;/span&gt;  &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So this last &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense&lt;/span&gt; layer takes its input (&lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;10&lt;/span&gt; (the output of the previous layer) and adds the bias to give us &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;11&lt;/span&gt; parameters/weights. Since we defined the dense layer as: &lt;span style=&#34;font-family:Courier; font-size:1.0em;&#34;&gt;Dense(1)&lt;/span&gt; we are telling our neural network that we want a single output.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Great! So you now how they work and you just looked through a short example of how you could implement a RNN model using Keras.  In the next notebook we will do a full runthrough of creating and running a RNN on real data.&lt;/p&gt;

&lt;p&gt;Just as an aside, while the RNN we defined was cute and simple, in practice these simple RNNs are not used. The reason? Well, we run into the problem of vanishing gradients and exploding gradients.  The vanishing gradient problem is why folks use the more exotic recurrent neural network known as long short term memory (LSTM).  I won&amp;rsquo;t go over the details here, but you can think of LSTMs as an extended version of recurrent neural networks. LSTMs act like computers in that they can read, delete, and add to their &amp;lsquo;stored&amp;rsquo; memory. This allows them to &amp;lsquo;extend&amp;rsquo; their &amp;lsquo;short term memory&amp;rsquo; to &amp;lsquo;longer short term memory&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;If you are curious, I suggest checking this blog by &lt;a href =&#39;https://medium.com/deep-math-machine-learning-ai/chapter-10-1-deepnlp-lstm-long-short-term-memory-networks-with-math-21477f8e4235&#39;&gt;Madhu Sanjeevi&lt;/a&gt;. It&amp;rsquo;s one of my favorite explainations of LSTMs.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h3&gt;About this Notebook&lt;/h3&gt;  

&lt;p&gt;The above example and code is from Ch.6 of Chollet&amp;rsquo;s &lt;i&gt;Deep Learning with Python&lt;/i&gt;[1]. Content was added for further clarification and readability.&lt;/p&gt;

&lt;p&gt;Jupyter Notebook by: Noah Luna&lt;/p&gt;

&lt;h3&gt;Suggested Reading Material&lt;/h3&gt;  

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Géron, A. (2017). Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems. O&amp;rsquo;Reilly UK Ltd.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Karpath, Andrej. &amp;ldquo;The Unreasonable Effectiveness of Recurrent Neural Networks&amp;rdquo; &lt;i&gt;Andrej Karpathy blog&lt;/i&gt;, 24 March 2017, &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34; target=&#34;_blank&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sanjeevi, Madhu. &amp;ldquo;DeepNLP — LSTM (Long Short Term Memory) Networks with Math&amp;rdquo; &lt;i&gt;Medium&lt;/i&gt;, 21 Jan 2018, &lt;a href=&#34;https://medium.com/deep-math-machine-learning-ai/chapter-10-1-deepnlp-lstm-long-short-term-memory-networks-with-math-21477f8e4235&#34; target=&#34;_blank&#34;&gt;https://medium.com/deep-math-machine-learning-ai/chapter-10-1-deepnlp-lstm-long-short-term-memory-networks-with-math-21477f8e4235&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Sources&lt;/h3&gt;  

&lt;ul&gt;
&lt;li&gt;[1]Chollet, F. (2017). Deep Learning with Python. Manning Publications.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;
</description>
    </item>
    
  </channel>
</rss>
